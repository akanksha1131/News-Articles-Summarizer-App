Article Title,Article Link,Article Text,Article Summary,Article Image
"$200 billion that continues to ‚Äòfrighten‚Äô Amazon investors, as company's shares post their longest streak of daily losses in almost 20 years, $463 billion wiped out",https://timesofindia.indiatimes.com/technology/tech-news/200-billion-that-continues-to-frighten-amazon-investors-as-companys-shares-post-their-longest-streak-of-daily-losses-in-almost-20-years-463-billion-wiped-out/articleshow/128331971.cms,"$200 billion that continues to ‚Äòfrighten‚Äô Amazon investors, as company's shares post their longest streak of daily losses in almost 20 years, $463 billion wiped out","Amazon's shares post their longest streak of daily losses in almost 20 years. $463 billion wiped out. $200 billion that continues to ‚Äòfrighten‚Äô Amazon investors, according to one analyst. Amazon shares are down 6.7% on Monday.","https://static.toiimg.com/thumb/msid-128331952,imgsize-36128,width-400,resizemode-4/layoffs-at-amazon.jpg"
US FTC to probe Microsoft's business practices that Google had called 'problematic' in and complained about in Europe,https://timesofindia.indiatimes.com/technology/tech-news/us-ftc-to-probe-microsofts-business-practices-that-google-had-called-problematic-in-and-complained-about-in-europe/articleshow/128331251.cms,"FILE - (AP Photo/Thibault Camus, File)

What is FTC asking Microsoft customers and rivals

Google's complaint against Microsoft

What Microsoft says on its Cloud practices

Amazon AWS also under FTC scrutiny

Microsoft is reportedly facing scrutiny by the US Federal Trade Commission (FTC). According to a report in Bloomberg, FTC is accelerating scrutiny of Microsoft as part of an ongoing probe into whether the company illegally monopolizes large swaths of the enterprise computing market with its cloud software and AI offerings, including Copilot. The agency has reportedly issued civil investigative demands in recent weeks to companies that compete with Microsoft in the business software and cloud computing markets. FTC has asked these companies a list of questions on Microsoft‚Äôs licensing and other business practices, says the report quoting people, who are said to have been granted anonymity to discuss a confidential investigation.With the demands, which are effectively like civil subpoenas, FTC is reportedly seeking evidence to check if Microsoft makes it harder for customers to use Windows, Office and other products on rival cloud services. The American agency is also requesting information on Microsoft‚Äôs bundling of artificial intelligence, security and identity software into other products, including Windows and Office, some of the people said. The probe is now in the hands of FTC Chairman Andrew Ferguson. Most of the questions are said to have zeroed in on Microsoft‚Äôs licensing practices. About a third of them focused on the company‚Äôs AI business and reflected concerns that Microsoft canceled some of its own work after investing in OpenAI and leaning heavily on its software, eliminating potential competition.Incidentally, Google filed a complaint with the European Commission in September 2024, saying Microsoft was exploiting its dominant Windows Server operating system to prevent competition. Google complained that Microsoft's anti-competitive practices locked customers into Microsoft's cloud platform Azure. However, in November 2025, Google dropped its EU antitrust complaint about Microsoft's cloud computing practices, a week after EU regulators launched an investigation to see if Microsoft should be subject to rules aimed at curbing its power in this sector. ""Today, we are withdrawing it (Microsoft complaint) in light of the recent announcement that the EC will assess problematic practices affecting the cloud sector under a separate process,"" Giorgia Abeltino, head of government affairs and public policy for Google Cloud Europe, said in a blog post. ""We continue to work with policymakers, customers, and regulators across the EU, the UK, and elsewhere to advocate for choice and openness in the cloud market,"" she said.Microsoft on its part has also said that some of its products aren‚Äôt fully interoperable with rival clouds because the technology underpinning some features is different. Additionally, a series of damaging hacks has put increasing pressure on the company to offer more robust security features in its core products.The FTC is also pressing ahead with a similar effort targeting Amazon. Both cases date back to Donald Trump's first term. Amazon leads the cloud computing market with a 30% share, followed by Microsoft at 20% and Google at 13%.","FTC reportedly seeking evidence to check if Microsoft makes it harder for customers to use Windows, Office and other products on rival cloud services. The agency is also requesting information on Microsoft‚Äôs bundling of artificial intelligence, security and identity software into other products, including Windows and Office.","https://static.toiimg.com/thumb/msid-128331235,imgsize-110900,width-400,resizemode-4/microsoft-results.jpg"
"Bill Gates is reportedly selling the house for which few months he said: I like this house, my kids like to come back here and that ‚Ä¶",https://timesofindia.indiatimes.com/technology/tech-news/bill-gates-is-reportedly-selling-the-house-for-which-few-months-he-said-i-like-this-house-my-kids-like-to-come-back-here-and-that-/articleshow/128323287.cms,"""nestled into one of Medina's most coveted hillsides"".

‚ÄúMy house in Seattle, I admit, is gigantic. My sisters have downsized. I can‚Äôt.

I like the houses I have. My kids like to come back‚Äîthat is a luxury. I don‚Äôt cook, I don‚Äôt make my own bed, but I don‚Äôt mind if no one has made it‚ÄîI wouldn‚Äôt notice.‚Äù

Bill Gates is now one of America‚Äôs largest private farmland owners



""less than 1/4000 of the farmland in the US""

""all these decisions are made by a professional investment team""","Bill Gates is now one of America‚Äôs largest private farmland owners. He owns less than 1/4000 of the farmland in the US. Gates: ""I don't cook, I don't make my own bed, but I don‚Äôt mind if no one has made it""","https://static.toiimg.com/thumb/msid-128323292,imgsize-52732,width-400,resizemode-4/bill-gates-is-reportedly-selling-the-house-for-which-few-months-he-said-i-like-this-house-my-kids-like-to-come-back-here-and-that-.jpg"
China‚Äôs Baidu adds AI Agent in Search app for 700 million users that companies in Korea have 'restricted' and security companies are warning users about,https://timesofindia.indiatimes.com/technology/tech-news/chinas-baidu-adds-ai-agent-in-search-app-for-700-million-users-that-companies-in-korea-have-restricted-and-security-companies-are-warning-users-about/articleshow/128320638.cms,"(AP Photo/Ng Han Guan)

What is OpenClaw

‚ÄòOpenClaw‚Äô AI Agents worry security researchers

Baidu reportedly plans to give users of its main smartphone app direct access to the wildly popular artificial intelligence tool OpenClaw. According to the Chinese tech company, starting later on Friday (February 13), users who opt in can message the AI agent through Baidu‚Äôs main search app to complete tasks such as scheduling, organizing files and writing code. Baidu claims 700 million monthly active users for its search app. The company is also said to be rolling out OpenClaw‚Äôs capabilities to its e-commerce business and other services.OpenClaw gained attention this week after the emergence of a new social network called Moltbook that is advertised as being exclusively for the use of OpenClaw bots. Cybersecurity firm Wiz said last weel that the network had a major flaw that exposed private data on thousands of people.OpenClaw, an open-source AI agent previously known as Clawdbot and Moltbot, is a powerful personal assistant that can connect to LLMs, integrate with external APIs, and autonomously execute an array of tasks like sending email or controlling browsers. OpenClaw is installed on local machines or dedicated servers. It stores configuration data and interaction history locally, which allows its behavior to persist across sessions.Because it‚Äôs designed to run locally, users often give it expansive access to terminal, files, and in some cases, root-level execution privileges.While OpenClaw carries the promise of AI-driven productivity, it also presents growing security concerns. Cybersecurity companies including CrowdStrike have warned the public about granting OpenClaw unfettered access to enterprise systems.Last week, China's industry ministry warned that the OpenClaw open-source AI agent, which gained global popularity in recent weeks, could pose significant security risks when improperly configured and expose users to cyberattacks and data breaches. The country's Ministry of Industry and Information Technology said it had discovered instances where users were operating OpenClaw with inadequate security settings and said better precautions needed to be taken.In South Korea, major technology companies including Kakao, Naver, and Karrot Market, are restricting the use of the open-source AI agent OpenClaw over security concerns. Companies cited risks related to data privacy, potential leaks, and system manipulation. Kakao and Naver told employees to avoid using OpenClaw on work devices, while Karrot Market blocked both access and use of OpenClaw and Moltbot.Kakao said it was restricting the tool, previously known as ClaudeBot or MaltBot, to safeguard corporate information assets. Naver has issued a similar internal ban, while Danggeun has blocked access entirely, citing risks beyond the company‚Äôs control. While none of these companies have formally announced a ban on OpenClaw, online workplace forums suggest internal security teams are monitoring its use.Microsoft‚Äôs AI safety team too has publicly questioned whether the tool is secure enough for enterprise use.","Baidu reportedly plans to give users of its main smartphone app direct access to the popular artificial intelligence tool OpenClaw. Users who opt in can message the AI agent through Baidu‚Äôs main search app to complete tasks such as scheduling, organizing files and writing code.","https://static.toiimg.com/thumb/msid-128320607,imgsize-87232,width-400,resizemode-4/china-baidu.jpg"
US withdraws tech blacklist an hour after adding two of biggest Chinese companies,https://timesofindia.indiatimes.com/technology/tech-news/us-withdraws-tech-blacklist-an-hour-after-adding-two-of-biggest-chinese-companies/articleshow/128317845.cms,"Representative image.

List of companies added and removed from tech blacklist



The US government on Friday (February 13) withdrew a newly updated list of Chinese companies allegedly aiding Beijing‚Äôs military, just one hour after it was made public, a report has said. The list, known as the Pentagon's 1260H list, originally appeared on the official Federal Register with several new, high-profile additions, including tech giants Alibaba and Baidu, a repot by news agency Reuters said.However, the link was quickly replaced with a ‚Äúwithdrawn‚Äù notice following an urgent request from the agency. No official reason for the reversal has been provided, the report added.‚ÄúAn agency letter requesting withdrawal of this document was received after placement on public inspection,‚Äù the Federal Register posted in an editorial note.The update included some of China's most recognisable global brands. Along with Alibaba and Baidu, the list reportedly added BYD, which is one of the world‚Äôs largest electric vehicle manufacturers and is a competitor to Elon Musk‚Äôs Tesla. Other companies included major biotechnology firm WuXi AppTec and RoboSense, a leader in AI-driven robotics.The list already includes major Chinese firms such as Tencent Holdings, one of China's largest tech companies, and CATL, a major battery maker in the electric vehicle industry.An Alibaba spokesperson said there was no basis for their inclusion and threatened legal action.‚ÄúAlibaba is not a Chinese military company nor part of any military-civil fusion strategy,‚Äù the company was quoted as saying.Conversely, chip memory maker YMTC was reportedly removed from the updated roster. It is to be noted that being on this list does not trigger immediate sanctions but it carries a heavy stigma. Reuters reported that under a recently passed law, the Pentagon will be prohibited from signing contracts or buying products from any company featured on the list in the coming years.","The list, known as the Pentagon's 1260H list, originally appeared on the official Federal Register with several new, high-profile additions. The link was quickly replaced with a ‚Äúwithdrawn‚Äù notice following an urgent request from the agency. No official reason for the reversal has been provided.","https://static.toiimg.com/thumb/msid-128317821,imgsize-47036,width-400,resizemode-4/us-china.jpg"
"Amazon deploys 32 satellites in orbit for internet, French President Emmanuel Macron says ‚Äòpackage delivered‚Äô",https://timesofindia.indiatimes.com/technology/tech-news/amazon-deploys-32-satellites-to-orbit-for-internet-french-president-emmanuel-macron-says-package-delivered/articleshow/128317062.cms,"Why this launch was big for Amazon and Europe



Amazon has successfully completed its first heavy-lift mission of 2026, marking a major milestone for both the tech giant and European space efforts. The Ariane 64 rocket lifted off from French Guiana, carrying 32 new satellites for Amazon‚Äôs growing internet constellation. Amazon is the second major company after Elon Musk‚Äôs SpaceX that is working to deploy satellites in space to provide fast, reliable high-speed internet to people worldwide who live beyond the reach of traditional cable or fiber networks.The mission, dubbed Leo Europe 01 (LE-01), is the first of 18 planned launches between Amazon and Arianespace, the company said. This launch brings Amazon‚Äôs total satellite count to over 200 spacecraft. The company said that Amazon plans to begin rolling out internet services to customers later in 2026 with initial service scheduled to start in the far northern and southern parts of the world.Panos Panay, who leads Amazon‚Äôs devices and services business, said: ‚ÄúCongrats to the @Amazonleo and @Arianespace teams! üöÄ LE-01 successfully deployed 32 satellites on our first Ariane 6 mission. Our biggest payload yet, and just the start of our 2026 heavy lift campaigns.So proud.‚ÄùThe LE-01 mission is the first time the Ariane 6 rocket launched with four boosters, making it the most powerful launcher currently available in Europe. Moreover, Amazon‚Äôs partnership with Arianespace is the largest commercial contract in the launch provider‚Äôs history.French President Emmanuel Macron celebrated the event on social media, declaring, ""Amazon, your package has been delivered,"" while hailing the launch as a ‚ÄúEuropean success.‚Äù‚ÄúAmazon, your package has been delivered. Ariane 6 has lifted off for the first time with four boosters, making it our most powerful European launcher!‚Äù Macron said.‚ÄúOn board: 32 satellites for Amazon‚Äôs constellation. Amazon chose Europe for this major launch. A French feat, a European success: we‚Äôre reaching new heights. Congratulations to the teams,‚Äù the President added.","Amazon has successfully completed its first heavy-lift mission of 2026. The mission, dubbed Leo Europe 01 (LE-01), is the first of 18 planned launches between Amazon and Arianespace. The launch brings Amazon‚Äôs total satellite count to over 200 spacecraft. Amazon plans to begin rolling out internet services to customers later in 2026 with initial service scheduled to start in the far northern and southern parts of the world.","https://static.toiimg.com/thumb/msid-128317053,imgsize-59352,width-400,resizemode-4/amazon-leo.jpg"
Google‚Äôs Waymo is offering DoorDash drivers new ‚Äòrobotaxi gig‚Äô: Here‚Äôs what the companies said,https://timesofindia.indiatimes.com/technology/tech-news/googles-waymo-is-offering-doordash-drivers-new-robotaxi-gig-heres-what-the-companies-said/articleshow/128315670.cms,"What Waymo and DoorDash said about the new gig



""In the rare event a vehicle door is left ajar, preventing the car from departing, nearby Dashers are notified, allowing Waymo to get its vehicles back on the road quickly,""","""In the rare event a vehicle door is left ajar, preventing the car from departing, nearby Dashers are notified,"" Waymo says. ""This allows Waymo to get its vehicles back on the road quickly,"" DoorDash says.","https://static.toiimg.com/thumb/msid-128315630,imgsize-58144,width-400,resizemode-4/googles-waymo-is-offering-doordash-drivers-new-robotaxi-gig-heres-what-the-companies-said.jpg"
Google CEO Sundar Pichai thinks Bloodbath in markets worldwide in reaction to Anthropic‚Äôs AI tool is...,https://timesofindia.indiatimes.com/technology/tech-news/google-ceo-sundar-pichai-thinks-bloodbath-in-markets-worldwide-in-reaction-to-anthropics-ai-tool-is-/articleshow/127927923.cms,"Google CEO Sundar Pichai and Nvidia CEO Jensen Huang dismiss market panic over AI plugins, calling it overblown. Despite a significant selloff in software stocks triggered by Anthropic's legal AI tools, they argue AI will enhance, not replace, existing software, enabling greater productivity and innovation.

Nvidia's Huang chimes in with Pichai, calls selloff 'most illogical thing in the world'

What exactly triggered the selloff

India‚Äôs AI Rise Gets Global Push As UN Chief Praises Leadership, Nvidia CEO Predicts Job Surge

Why the fear runs deeper than one plugin

Google CEO Sundar Pichai isn't buying the panic. During the company's earnings call, Pichai pushed back against the market hysteria triggered by Anthropic's new AI plugins, calling it overblown. AI is ""an enabling tool,"" he said, just as it has been for Google 's own products‚ÄîSearch, YouTube and others. Companies ""seizing the moment"" will find the same opportunity ahead, he added.His comments come as software stocks worldwide nurse heavy losses. Anthropic's Claude Cowork plugins, wiped out roughly $285 billion from software, legal tech and financial services stocks in a single session. Analysts dubbed it a 'SaaSpocalypse'. Pichai's view? The scramble is overdone.Pichai isn't alone in questioning the market reaction. Nvidia CEO Jensen Huang was even more direct at a Cisco event, calling the selloff ""the most illogical thing in the world."" His take: AI will use existing software tools, not reinvent them. ""Would you use a screwdriver or invent a new screwdriver?"" he asked. Huang added that Nvidia itself has adopted such tools extensively, freeing up employees to focus on designing chips and computer systems.Software company executives have also pushed back, arguing they do far more than just build code. Their offerings include data management and purpose-built solutions that are difficult to replicate, especially for enterprises outside the tech world like retail and oil and gas.Anthropic released 11 open-source plugins for Claude Cowork, its agentic AI assistant for non-technical professionals. Most covered standard enterprise functions‚Äîsales, marketing, finance, customer support. But the legal plugin rattled nerves. It automates contract review, NDA triage, compliance checks and legal briefings.Morgan Stanley analyst Toni Kaplan called it ""a sign of intensifying competition"" that could hurt big players in the legal space. The fallout was swift. Thomson Reuters and RELX both closed down around 15%. LegalZoom crashed nearly 20%. Indian IT stocks weren't spared‚ÄîInfosys ADRs slipped 5.5%, Wipro fell nearly 5%.The concern isn't just about legal workflows. There's a dawning realisation that AI tools can now do far more than most non-techies realise. With relatively simple prompts, they can take over a user's computer, write software, analyse stock market data, manage emails and countless other tasks. People have taken to social media describing how they built their first software program without ever learning to code. Shopify's CEO built software that could interpret his recent MRI.Meta's CFO Susan Li told investors last week that the company has seen a 30% year-over-year increase in output per engineer driven by AI coding tools. Power users have seen an 80% boost.Anthropic's numbers back up the concern. Claude Code hit $1 billion in annualised recurring revenue by November, months after launch. The company is reportedly raising $20 billion at a $350 billion valuation. Jefferies noted that OpenAI is losing corporate ground to Claude, with enterprises now making up 80% of Anthropic's business.Pichai and Huang are betting the panic subsides. Wall Street isn't so sure yet.","Google CEO Sundar Pichai and Nvidia CEO Jensen Huang dismiss market panic over AI plugins, calling it overblown. Despite a significant selloff in software stocks triggered by Anthropic's legal AI tools, they argue AI will enhance, not replace, existing software.","https://static.toiimg.com/thumb/msid-127927923,imgsize-19166,width-400,resizemode-4/127927923.jpg"
OpenAI is reportedly seeing exit of senior-level employees after CEO Sam Altman makes it compulsory to use‚Ä¶,https://timesofindia.indiatimes.com/technology/tech-news/openai-is-reportedly-seeing-exit-of-senior-level-employees-after-ceo-sam-altman-makes-it-compulsory-to-use/articleshow/127909390.cms,"OpenAI is facing a talent drain as senior researchers depart. CEO Sam Altman is focusing resources on ChatGPT, impacting experimental projects. This shift follows competitive pressure from rivals like Google and Anthropic. Teams working on video and image generation feel sidelined. The company's strategic pivot aims to maintain its lead in the rapidly evolving AI landscape.","OpenAI is facing a talent drain as senior researchers depart. CEO Sam Altman is focusing resources on ChatGPT, impacting experimental projects. This shift follows competitive pressure from rivals like Google and Anthropic. The company's strategic pivot aims to maintain its lead in the rapidly evolving AI landscape.","https://static.toiimg.com/thumb/msid-127909390,imgsize-1145864,width-400,resizemode-4/127909390.jpg"
Google crosses $400 billion revenue mark for the first time; Elon Musk reacts,https://timesofindia.indiatimes.com/technology/tech-news/google-crosses-400-billion-revenue-mark-for-the-first-time-elon-musk-reacts/articleshow/127923956.cms,"Elon Musk On EU Radar; X‚Äôs AI Chatbot Grok Faces Biggest Probe Over Sexual Deepfakes | Details

What Sundar Pichai said about Google‚Äôs Q4 results

‚ÄúIt was a tremendous quarter for Alphabet and annual revenues exceeded $400 billion for the first time. The launch of Gemini 3 was a major milestone and we have great momentum. Our first party models, like Gemini, now process over 10 billion tokens per minute via direct API use by our customers, and the Gemini App has grown to over 750 million monthly active users. Search saw more usage than ever before, with AI continuing to drive an expansionary moment. We continue to drive strong growth across the business.

YouTube‚Äôs annual revenues surpassed $60 billion across ads and subscriptions; we now have over 325 million paid subscriptions across consumer services, led by strong adoption for Google One and YouTube Premium. And Google Cloud ended 2025 at an annual run rate of over $70 billion, representing a wide breadth of customers, driven by demand for AI products. We‚Äôre seeing our AI investments and infrastructure drive revenue and growth across the board. To meet customer demand and capitalize on the growing opportunities we have ahead of us, our 2026 CapEx investments are anticipated to be in the range of $175 to $185 billion.‚Äù","Sundar Pichai: ""It was a tremendous quarter for Alphabet and annual revenues exceeded $400 billion for the first time"" YouTube‚Äôs annual revenues surpassed $60 billion across ads and subscriptions. Google Cloud ended 2025 at an annual run rate of over $70 billion.","https://static.toiimg.com/thumb/msid-127923946,imgsize-22668,width-400,resizemode-4/google-crosses-400-billion-revenue-mark-for-the-first-time-elon-musk-reacts.jpg"
Oracle's Larry Ellison has lost almost $50 billion this year in less than forty days,https://timesofindia.indiatimes.com/technology/tech-news/oracles-larry-ellison-has-lost-almost-50-billion-this-year-in-less-than-forty-days/articleshow/127967875.cms,"Ellison was not alone other tech leaders also hit hard

Oracle‚Äôs risky AI bet

Oracle cofounder Larry Ellison has now seen an unprecedented $50 billion wiped off his net worth in less than forty days this year, as per Bloomberg Billionaires Index. Ellison‚Äôs fortune stood at $199 billion by Wednesday‚Äôs (February 4) close, down sharply from $247 billion at the start of January. A single-day slump of 5% in Oracle‚Äôs stock erased about $9 billion from this wealth, deepening the decline.The round in software stocks was triggered by Anthropic‚Äôs release of plugins for its Claude Cowork AI agent, which can easily automate corporate tasks in legal, scales, finance, marketing and data analysis. Investors now fear that such tools could lead to reduction in the demand for external software from established giants such as Adobe, Salesforce, Intuit and Atlassian. Shares of all these companies tumbled earlier this week before staging a particle rebound, but Oracle‚Äôs loses remained steep.Ellison was not along in facing the sharp decline in net worth. Along with him, Tesla CEO Elon Musk also saw his net worth fall by around $11 billion, while Meta CEO Mark Zuckerberg lost around $8 billion. On the other hand, other tech leaders like Larry Page, Sergey Brin, Jeff Bezos and Jensen Huang each shed around $5 billion as the stocks of the companies dropped by at least 2%.For those unaware, Oracle has aggressively positioned itself as an important player in the AI boom, the company has signed deals with Nvidia and OpenAI in order to offer data centers powering next-generation technology. However, its heavy spending and increasing debt have raised concerns among analysts. The company‚Äôs remaining performance obligations ‚Äî contracted sales not yet recognized as revenue ‚Äî surged 438% year-over-year to $523 billion as of November 30, nearly ten times its annual revenue of $53 billion.Critics believe that Oracle may be overspending. Popular American investor Michael Burry has publicly bet against Oracle. Burry has warned that the company‚Äôs debt-fueled expansion tied to AI contracts was unnecessary, calling the moves ‚Äúhard to explain‚Äù and suggesting that ‚Äúego‚Äù might be driving decisions.","Ellison's fortune stood at $199 billion by Wednesday‚Äôs (February 4) close, down sharply from $247 billion at the start of January. A single-day slump of 5% in Oracle's stock erased about $9 billion from this wealth. Tesla CEO Elon Musk also saw his net worth fall by around $11 billion.","https://static.toiimg.com/thumb/msid-127967862,imgsize-44470,width-400,resizemode-4/larry-ellison.jpg"
Microsoft appoints 'Engineering Quality Czar'; CEO Satya Nadella to employees in memo: I have asked Charlie Bell to take on‚Ä¶,https://timesofindia.indiatimes.com/technology/tech-news/microsoft-appoints-engineering-quality-czar-ceo-satya-nadella-to-employees-in-memo-i-have-asked-charlie-bell-to-take-on/articleshow/127971737.cms,"Microsoft CEO Satya Nadella has reshaped leadership, prioritizing engineering quality and cybersecurity. Charlie Bell transitions to an 'engineering quality czar' role, reporting directly to Nadella, focusing on improving product reliability. Hayete Gallot returns to lead security operations, bringing a blend of sales and engineering expertise to bolster Microsoft's security offerings and customer value.

Satya Nadella Recounts 2023 Story Of Indian Farmer Leveraging AI Bot For Subsidies

Bell moves from managing 10,000 people to flying solo as an IC

Gallot brings a sales-meets-engineering playbook back to Redmond

Why Microsoft needs a quality czar right now

Microsoft CEO Satya Nadella has shuffled two of his top lieutenants in a move that puts engineering quality and cybersecurity front and centre. Charlie Bell, who led the company's security operations since 2021, is stepping down from that role to become what's effectively an engineering quality czar‚Äîreporting directly to Nadella.""Charlie and I have been planning this transition for some time, given his desire to move from being an org leader to being an IC engineer,"" Nadella wrote in an internal memo shared on Wednesday. ""And I love how energized he is to practice this craft here day in and day out!""Bell's replacement? Hayete Gallot, who's returning to Microsoft after an 18-month stint as Google Cloud's President of Customer Experience. She previously spent over 15 years at Redmond, climbing to the rank of corporate vice president across Windows, Office, and security teams.The shift is significant. Bell oversaw a team of roughly 10,000 people and was the driving force behind Microsoft's Secure Future Initiative‚Äîa company-wide push launched after Chinese hackers breached US government email accounts through a Microsoft Cloud exploit in 2023. That incident triggered a scathing review from the Department of Homeland Security, which called Microsoft's security culture ""inadequate.Now, Bell will work closely with cloud and AI chief Scott Guthrie and Mala Anand on what Nadella calls the ""Quality Excellence Initiative."" The initiative is aimed at delivering ""durable, high-quality experiences at global scale""‚Äîcorporate speak that likely translates to fewer Azure outages, fewer broken Windows patches, and fewer out-of-band emergency fixes.Gallot's appointment signals a shift in how Microsoft thinks about its security business. Nadella specifically highlighted her ability to combine ""product building with value realization for customers."" She'll also oversee Ales Holecek, who takes on a newly created Chief Architect for Security role.The timing isn't random. During last week's earnings call, Nadella talked up momentum in security products like Security Copilot agents and Purview. The company clearly wants someone who can sell security as aggressively as they build it.Nadella's memo doesn't spell out exactly why engineering quality needs its own dedicated leader at this moment. But the clues aren't hard to find. Microsoft now uses AI to write around 30 percent of its own code, Azure outages remain a recurring headache, and Copilot adoption sits at a modest 3.3 percent among Microsoft 365 users. Bell's got his work cut out.","Microsoft CEO Satya Nadella shuffled two of his top lieutenants in a move that puts engineering quality and cybersecurity front and centre. Charlie Bell, who led the company's security operations since 2021, is stepping down from that role to become what's effectively an engineering quality czar. Bell's replacement? Hayete Gallot, who's returning to Microsoft after an 18-month stint as Google Cloud's President of Customer Experience.","https://static.toiimg.com/thumb/msid-127971737,imgsize-110876,width-400,resizemode-4/127971737.jpg"
Amazon layoffs: Company to cut thousands of jobs as it closes Fresh stores; here are options that employees have: Get severance pay or ...,https://timesofindia.indiatimes.com/technology/tech-news/amazon-layoffs-company-to-cut-thousands-of-jobs-as-it-closes-fresh-stores-here-are-options-that-employees-have-get-severance-pay-or-/articleshow/127965037.cms,"Amazon giving these options to employees



Transfer opportunities for employees



Why Amazon is shutting down Amazon Go and Fresh stores

Amazon recently announced that it is shutting down its Amazon Fresh supermarket chain. The decision of the company to shut down the Amazon Fresh stores will lead to thousands of job cuts across the US. Last week, the e-commerce major announced that it will close around 60 Fresh stores which will put an end to the effort of six-years. As reported by Business Insider, the WARN notices filed in various states confirm the sale of layoffs. As aper the filling, in California only the company will shut down 20 Fresh stores which will affect around 3,900 workers. Most Fresh locations closed to the public on February 1, though California stores will remain open until mid-March due to state law.As Amazon is shutting down the Fresh stores, it has outlined two main options for the affected employees. The company is giving a choice to the employees in which they can either choose the severance pay or can take transfer within the company. The workers will continue to receive their normal pay and benefits for 90 days after the closure announcement, or until April 28. The compensation offered by the company will be based on either the minimum pay for their employee class of their average hours worked over the past 60 days whichever is higher.The report further adds that employees who do not secure another role within the company by late April will then receive severance packages, calculated as one week of pay for every six months of service at Amazon Fresh. Workers are guaranteed a minimum of four weeks‚Äô pay, with the possibility of up to 20 weeks depending on tenure.For those seeking to remain within Amazon, the company is encouraging Fresh workers to apply for similar positions at Whole Foods Stores or Amazon grocery warehouse via its internal A to Z portal. An Amazon spokesperson said: ‚ÄúAll affected employees will have the opportunity to apply for open roles within Amazon where available, and we‚Äôre providing career transition services to help them explore options.‚ÄùAmazon Fresh associates typically earned between $16 and $20 per hour, according to data from job site Indeed. Their responsibilities ranged from picking delivery orders to handling checkout operations.Amazon Go and Fresh stores were introduced as Just Walk Out technology, but they struggled to establish a distinctive customer experience and sustainable economic model. On the other hand, Whole Food Market acquired in 2017 by Amazon say strong growth with sales rising more than 40% in recent years. Also, Amazon‚Äôs online grocery business also witnessed a surge with perishable grocery sales through Same-Day Delivery growing 40x since January 2025, making fresh groceries one of the most-ordered categories on its platform.",Amazon recently announced that it is shutting down its Amazon Fresh supermarket chain. The decision of the company to shut down the Amazon Fresh stores will lead to thousands of job cuts across the US. The company is giving a choice to the employees in which they can either choose the severance pay or can take transfer within the company.,"https://static.toiimg.com/thumb/msid-127965035,imgsize-32816,width-400,resizemode-4/amazon.jpg"
Meet Anthropic CEO Dario Amodei: Former OpenAI researcher who turned his AI vision into a $3.7 billion company,https://timesofindia.indiatimes.com/technology/tech-news/meet-anthropic-ceo-dario-amodei-former-openai-researcher-who-turned-his-ai-vision-into-a-3-7-billion-company/articleshow/127943143.cms,"Source: Bloomberg

Anthropic CEO Dario Amodei‚Äôs academic background and early career path



Dario Amodei‚Äôs rise at OpenAI and the birth of GPT models



Dario Amodei leaves OpenAI and builds Anthropic



Dario Amodei‚Äôs cautious leadership style



Dario Amodei is the CEO and co-founder of Anthropic, one of the most closely watched AI companies in the world right now. He is not a loud public figure, and he rarely chases attention, but his work has quietly shaped how modern AI systems are built and controlled. Before running a multi-billion-dollar company, Amodei spent years in labs and research roles, studying complex systems and how they behave under pressure. That background still shows in how he talks about artificial intelligence today. While others focus on speed and scale, he appears more concerned with safety, limits, and long-term risks. As AI moves faster than regulation, Amodei‚Äôs cautious approach is becoming harder to ignore.Before AI became the world‚Äôs favourite buzzword, Amodei was deep in academia. He studied physics at Stanford University and later earned a PhD in biophysics from Princeton. At the time, he was focused on understanding complex biological systems. Cells. Signals. Patterns that emerge rather than being designed. Looking back, that mindset fits AI almost too well.After completing his doctorate, he worked as a postdoctoral researcher at Stanford University School of Medicine.There was no clear path to becoming a tech billionaire. That part came later. Almost accidentally, it seems. Amodei eventually moved into machine learning research, joining companies like Baidu and Google Brain. At Google, he worked on neural networks and AI safety.Colleagues from that period say he already seemed concerned about failure modes. In 2016, he joined OpenAI. Things moved fast after that.At OpenAI, Amodei rose quickly. By 2019, he was Vice President of Research, helping set the organisation‚Äôs overall research direction. He led work on GPT-2 and GPT-3, models that changed public perception of AI almost overnight.These systems could write essays, answer questions, and even mimic conversation. Sometimes convincingly. Sometimes awkwardly. During this time, Amodei also co-invented reinforcement learning from human feedback. RLHF sounds technical, but the idea is simple. Teach AI systems by showing them what humans actually prefer, not just what scores well mathematically.In 2021, Amodei left OpenAI along with six others, including his sister Daniela Amodei. They founded Anthropic. Some people were sceptical at first. But Anthropic took a different route. It became a public benefit corporation. That detail mattered. It signalled that profit would not be the only priority. At least in theory. Their AI model, Claude, leaned into being cautious. Less dramatic. More restrained. That tone appealed to companies worried about reputational risk.By September 2025, Anthropic was reportedly valued at $183 billion by private investors. That number raised eyebrows. Especially for a company without much public hype.Partnerships with Alphabet and Amazon helped fuel that growth. So did rising concerns about AI safety across governments and corporations. As Anthropic‚Äôs valuation climbed, so did Amodei‚Äôs wealth. His real-time net worth now sits around $3.7 billion, ranking among the world‚Äôs richest people.Amodei does not sound like most tech CEOs. He hedges. A lot. ‚ÄúIt seems.‚Äù ‚ÄúIt might.‚Äù ‚ÄúWe‚Äôre not fully sure yet.‚Äù That language annoys some people. Others trust it more. He avoids grand predictions. No promises of utopia. No claims that AI will solve everything.Experts say his influence shows up in quieter ways. Safety research is becoming mainstream. Alignment discussions moving from fringe to boardroom. Competitors are copying ideas they once ignored. No one really knows what comes next for Dario Amodei. AI is moving fast. Faster than regulation.","Dario Amodei is the CEO and co-founder of Anthropic, one of the most closely watched AI companies in the world right now. He studied physics at Stanford University and later earned a PhD in biophysics from Princeton. At Google, he worked on neural networks and AI safety. He co-invented reinforcement learning from human feedback.","https://static.toiimg.com/thumb/msid-127944715,imgsize-23238,width-400,resizemode-4/meet-anthropic-ceo-dario-amodei-former-openai-researcher-who-turned-his-ai-vision-into-a-37-billion-company.jpg"
Apple CEO Tim Cook answers the ‚Äòbig‚Äô question: Why Google and not Sam Altman's OpenAI for new Siri,https://timesofindia.indiatimes.com/technology/tech-news/apple-ceo-tim-cook-answers-the-big-question-why-google-and-not-sam-altmans-openai-for-new-siri/articleshow/127794640.cms,"Apple has chosen Google's advanced Gemini AI for its new Siri and upcoming Apple Intelligence features, prioritizing superior technology over OpenAI. CEO Tim Cook emphasized this collaboration, assuring users of continued privacy standards. While OpenAI's ChatGPT integration remains, it's now seen as secondary. Apple views this AI integration as a significant value creator and potential revenue stream.","Apple has chosen Google's advanced Gemini AI for its new Siri and upcoming Apple Intelligence features. CEO Tim Cook emphasized this collaboration, assuring users of continued privacy standards. While OpenAI's ChatGPT integration remains, it's now seen as secondary.","https://static.toiimg.com/thumb/msid-127794640,imgsize-316737,width-400,resizemode-4/127794640.jpg"
"Oracle Layoffs: Oracle may lay off up to 30,000 employees, and one of the Big reasons is the company's 'commitment' to Sam Altman's OpenAI for‚Ä¶",https://timesofindia.indiatimes.com/technology/tech-news/oracle-may-lay-off-up-to-30000-employees-and-one-of-the-big-reasons-is-the-companys-commitment-to-sam-altmans-openai-for/articleshow/127835680.cms,"Oracle faces massive job cuts, potentially 20,000-30,000, to fund its costly $300 billion OpenAI partnership. The tech giant has already spent $58 billion on data centers and is struggling with rising borrowing costs as US banks retreat. This financial strain is impacting Oracle's ability to deliver crucial AI infrastructure.

'OpenAI deal is eating Oracle alive financially'

OpenAI's Master Plan for India

US banks are pulling back‚Äîand that's a big problem

A possible Cerner sale and 40% upfront customer deposits show how tight things have gotten

Oracle is staring down the possibility of its largest-ever workforce reduction‚Äîand at the heart of it is a $300 billion partnership with OpenAI that's proving far more expensive than anyone initially let on.Investment bank TD Cowen reported this week that Oracle is weighing cuts of 20,000 to 30,000 jobs. The move would free up an estimated $8 to $10 billion in cash flow, money the company desperately needs as it tries to bankroll a sprawling network of AI data centers built largely to serve Sam Altman 's company.TD Cowen puts the OpenAI commitment alone at around $156 billion in capital spending‚Äîand roughly 3 million GPUs to back it up. Oracle has already burned through $58 billion in debt in just two months. That's $38 billion for data centers in Texas and Wisconsin, $20 billion for a campus in New Mexico. Total debt now sits north of $100 billion.The kicker? That $58 billion covers only a slice of what's actually needed. Since its September 2025 peak, Oracle's stock has shed more than half its value‚Äîabout $463 billion in market cap, gone.The financing crunch isn't just an Oracle internal issue anymore.Multiple US banks have quietly retreated from lending on Oracle-linked data center projects. TD Cowen noted that lenders have roughly doubled the interest rate premiums they charge Oracle since September, pushing borrowing costs into territory usually reserved for junk-rated companies.The result? Several data center leases Oracle had been negotiating simply stalled. Private operators couldn't get the funding to build, which means Oracle can't deliver the capacity its customers‚Äîespecially OpenAI‚Äîare counting on. Some Asian banks are still willing to step in, but that doesn't solve the immediate problem in the US, where most of Oracle's expansion is planned.Oracle isn't sitting idle. The company is now requiring new customers to pay up to 40% of contract value upfront‚Äîessentially asking clients to co-fund the infrastructure. It's also exploring ""bring your own chip"" arrangements, where customers supply their own hardware.On the table too is a potential sale of Cerner, the healthcare software unit Oracle bought for $28.3 billion in 2022. That would be a significant strategic pivot, signaling that AI infrastructure is now the clear priority‚Äîeverything else is up for grabs.TD Cowen also flagged that OpenAI has already begun shifting some near-term capacity needs over to Microsoft and Amazon, which is not exactly a vote of confidence in Oracle's ability to deliver on schedule.The company has not publicly commented on the layoff reports or the financing difficulties.","Oracle faces massive job cuts, potentially 20,000-30,000, to fund its costly $300 billion OpenAI partnership. The tech giant has already spent $58 billion on data centers and is struggling with rising borrowing costs. This financial strain is impacting Oracle's ability to deliver crucial AI infrastructure.","https://static.toiimg.com/thumb/msid-127835680,imgsize-18640,width-400,resizemode-4/127835680.jpg"
"Egypt bans Roblox nationwide over child safety concerns, raising global questions about kids' online freedom",https://timesofindia.indiatimes.com/technology/tech-news/egypt-bans-roblox-nationwide-over-child-safety-concerns-raising-global-questions-about-kids-online-freedom/articleshow/127935398.cms,"Source: Bloomberg

Roblox faces a government ban in Egypt: Here‚Äôs why



What this ban means for kids and parents



Roblox going dark in Egypt, the platform that lives almost entirely on screens, the sudden loss felt very real. With games loading, Avatars running around blocky worlds. And then Egypt has officially banned Roblox, saying the move is about protecting children from harmful online content. The story underneath feels layered, political, and a little messy. Roblox looks harmless on the surface but experts say the risk is not the visuals but the interaction. The platform allows users to create games, chat with strangers, and move freely between user-generated worlds.A spokesperson confirmed the company has reached out to Egyptian authorities, offering dialogue to resolve the issue and restore access. The company says it has worked with regulators in other regions to build localised safety systems that align with cultural values. Last year, the company restricted some features across parts of the Middle East to address safety concerns. This ban did not come out of nowhere. Roblox has already been blocked or restricted in countries like Qatar and Turkey with other nations watching closely.The decision came from Egypt‚Äôs Supreme Council for Media Regulation.According to state-run media, the ban will be coordinated with the National Telecommunications Regulatory Authority. That means internet providers are expected to block access nationwide with no single official explanation was released at first. Later, state outlets pointed to growing concerns about children‚Äôs exposure to inappropriate content, online interactions, and psychological risks as reported by Bloomberg. An Egyptian senator had already called for regulating Roblox to protect children‚Äôs moral and educational values.President Abdel-Fattah El-Sisi recently called for limits on children‚Äôs phone use, pointing to similar moves abroad. Australia has banned social media for certain age groups. France is moving in the same direction. Egypt‚Äôs parliament is now discussing broader rules for digital platforms including unified age classifications, stronger verification, penalties and possibly forcing companies to have local representatives inside the country.For children, the ban feels abrupt and confusing. For parents, reactions are mixed. Some welcome the move, while others worry it pushes kids toward less visible, less regulated platforms, potentially exposing them to more risks. That is the irony experts often point out. When one door closes, another usually opens. Sometimes darker, more unpredictable, and harder to monitor.Still, supporters of the ban argue that Roblox‚Äôs scale makes it different. Millions of users. Constant interaction. Endless content that cannot realistically be watched, moderated, or controlled by humans alone, leaving significant safety and privacy concerns for young players and families.","The decision came from Egypt‚Äôs Supreme Council for Media Regulation. Last year, the company restricted some features across parts of the Middle East to address safety concerns. Roblox has already been blocked or restricted in countries like Qatar and Turkey with other nations watching closely. For children, the ban feels abrupt and confusing. For parents, reactions are mixed.","https://static.toiimg.com/thumb/msid-127935387,imgsize-30688,width-400,resizemode-4/egypt-bans-roblox-nationwide-over-child-safety-concerns-raising-global-questions-about-kids-online-freedom.jpg"
"Anime Paradox codes February 2026: Earn in-game gems, stat chips, and know how to redeem active codes",https://timesofindia.indiatimes.com/technology/gaming/anime-paradox-codes-february-2026-earn-in-game-gems-stat-chips-and-know-how-to-redeem-active-codes/articleshow/127834840.cms,"What is Roblox Anime Paradox and its active codes



Active Anime Paradox codes February 2026



15KLIKES! gives 5,000 Gems, 20 Stat Chips, and 10 Super Stat Chips.

1MVISITS! offers 3,500 Gems and 20 Trait Rerolls.

10KCCU rewards 500 Gems and 5 Trait Rerolls.

5KLIKES gives 500 Gems.

2.5KLIKES grants 250 Gems.

1KLIKES! adds another 250 Gems.

RELEASE! unlocks 500 Gems.

SORRYCODE is a big one, reportedly giving 15,000 Gems and 35 Trait Rerolls.

GEMSBUFFED! includes 5,000 Gems and 25 Trait Rerolls.

GIVEGEMSPLEASE hands out 7,000 Gems.

Anime Paradox expired codes



How to redeem Anime Paradox codes



Launch Anime Paradox on Roblox.

Look to the right side of the screen.

Click the blue Codes button.

Type or paste a working code into the grey box.

Hit the green Redeem button.

Anime-themed games on Roblox are everywhere right now. Some fade fast. Others stick around because they keep players coming back. Anime Paradox seems to fall into the second category. At first glance, it looks like another tower defence title with familiar anime faces and flashy attacks. But spend a little time with it, and the grind becomes obvious. Progress slows quickly, upgrades demand patience, and free rewards feel essential rather than optional for anyone hoping to stay competitive. Anime Paradox February codes let you redeem gems, stat chips, trait rerolls, and more.For players trying to build a decent team without sinking hours into farming, they matter.Below is the list of all working Anime Paradox codes in February 2026.Anime Paradox is a Roblox tower defence game where players summon and command powerful anime-style units to fend off waves of enemies and bosses as they defend a base. It blends classic tower defence mechanics with strategic placement and AI-controlled unit combat, so battles play out automatically once your units are deployed.Anime Paradox is built around summoning and upgrading units.That‚Äôs the loop. And like most Roblox games built this way, Gems sit at the centre of everything. It sounds simple, but the cost adds up quickly. Progress slows if you rely only on gameplay rewards. They give players a chance to catch up, try new units, or recover from a bad roll.As of the latest update, several Anime Paradox codes are still active.As per the recent updates, there are no expired Anime Paradox codes; however, this can change at any time.Redeeming codes in Anime Paradox is refreshingly simple. No hidden menus. No complicated steps.","Anime Paradox is a Roblox tower defence game. Players summon and command powerful anime-style units to fend off waves of enemies and bosses as they defend a base. It blends classic tower defence mechanics with strategic placement and AI-controlled unit combat, so battles play out automatically once your units are deployed.","https://static.toiimg.com/thumb/msid-127834907,imgsize-35490,width-400,resizemode-4/anime-paradox-codes-february-2026-earn-in-game-gems-stat-chips-and-know-how-to-redeem-active-codes.jpg"
Facebook-parent Meta wants to bring back technology it shut down 5 years ago,https://timesofindia.indiatimes.com/technology/tech-news/facebook-parent-meta-wants-to-bring-back-technology-it-shut-down-5-years-ago/articleshow/128315559.cms,"Launch timeline discussed in internal memos

The Privacy Debate Re-Ignited

'Exit India If...': Supreme Court Sends Sharp Message To Meta Over WhatsApp Policy, Indian User Data

Five years after shutting down its facial recognition system on Facebook over privacy fears, Meta is preparing for a comeback, a report has said. The tech giant is said to be working to bring the technology back with a change ‚Äì this time embedding it directly into the lenses of its popular Ray-Ban smart glasses. According to a report by The New York Times, the feature is internally dubbed ‚ÄúName Tag‚Äù, and it will allow glasses wearers to look at a person and instantly identify them. Moreover, they can also pull up information through Meta‚Äôs built-in AI assistant, the report noted, citing four people involved with the plans.The report, however, says that Meta‚Äôs plans may change. Citing an internal document, the company has been in talks how to release a feature that carries ‚Äúsafety and privacy risks‚Äù. The company reportedly considered a ‚Äúsoft launch‚Äù at a conference for the blind to showcase the tool‚Äôs helpfulness before a wider release.The report also cites internal memos which suggest that the company is looking for a strategic window to release the feature with minimal backlash.‚ÄúWe will launch during a dynamic political environment where many civil society groups that we would expect to attack us would have their resources focused on other concerns,‚Äù the document from Meta‚Äôs Reality Labs, which works on hardware including smart glasses, was cited as saying.Why Meta ‚Äòkilled‚Äô facial recognition techIn 2021, Meta deleted the face-scan data of over a billion people, citing the need to find the ‚Äúright balance‚Äù for a technology that sparked legal battles and public outcry. However, the commercial success of the Ray-Ban Meta smart glasses has reportedly reignited the company‚Äôs ambitions.The return of facial recognition on wearable devices has immediately set off alarm bells among privacy advocates. Unlike a static camera in a store, smart glasses are mobile and often go unnoticed, threatening the ""practical anonymity"" of everyday life.What Meta has to say on technology‚Äôs resintroductionMeta has not yet committed to a specific launch date and insists it is proceeding with caution.‚ÄúWe‚Äôre building products that help millions of people connect and enrich their lives. While we frequently hear about the interest in this type of feature ‚Äî and some products already exist in the market ‚Äî we‚Äôre still thinking through options and will take a thoughtful approach if and before we roll anything out,‚Äù Meta said in a statement.",Report: Meta is preparing for a comeback of its facial recognition technology. The tech giant is said to be working to bring the technology back with a change. It will embed it directly into the lenses of its popular Ray-Ban smart glasses. The feature is internally dubbed ‚ÄòName Tag‚Äô,"https://static.toiimg.com/thumb/msid-128315534,imgsize-81868,width-400,resizemode-4/ray-ban-meta-glasses.jpg"
"Google warns Europe: We deliver lot of value to you, and you are ...",https://timesofindia.indiatimes.com/technology/tech-news/google-warns-europe-we-deliver-lot-of-value-to-you-and-you-are-/articleshow/128311737.cms,"Google warns Europe: We deliver lot of value to you, and you are ...","Google warns Europe: We deliver a lot of value to you, and you are not getting enough of it. Google says it is working on a solution to the problem. The company says it has been in talks with the European Commission and the European Court of Justice.","https://static.toiimg.com/thumb/msid-128311723,imgsize-382460,width-400,resizemode-4/google.jpg"
China releases strict anti-monopoly rules for country‚Äôs tech giants: Key things to know,https://timesofindia.indiatimes.com/technology/tech-news/china-releases-strict-anti-monopoly-rules-for-countrys-tech-giants-key-things-to-know/articleshow/128310129.cms,"Ending exclusive partnerships



China AI rules to protect kids



China‚Äôs market watchdog has officially released a new set of anti-monopoly guidelines aimed at limiting the power of internet platforms. The rules, released on Friday (February 13), are designed to ensure fair competition and prevent platforms from charging unfairly high prices to consumers. One of the most significant parts of the new guidelines targets the algorithms of these platforms.According to a report by news agency Reuters, the government has warned companies against using sophisticated technology to coordinate pricing or traffic distribution with their competitors. The watchdog is also said to be putting an end to a common industry tactic known as ‚Äúall-network lowest price‚Äù requirements.This means that dominant platforms can no longer force sellers to lower their prices just because they offered a discount on a rival site. Moreover, the smaller platforms are now on notice, they can also face monopoly charges if they demand that merchants give them ‚Äúequal or better‚Äù deals than their competitors.The new guidelines strictly prohibit forced exclusive partnerships which means that major platforms are now banned from demanding that merchants pledge not to work with competing apps unless there is a justifiable reason.Platforms are also advised against using transaction history, device types, or spending habits to charge different prices to different users for the same service.In December last year, China proposed strict rules for artificial intelligence (AI) to safeguard children and prevent chatbots from offering advice that could lead to self-harm or violence. Under the proposed rules, developers will need to ensure their AI models do not generate content that promotes gambling. Once finalised, the rules will apply to AI products and services in China.","China‚Äôs market watchdog has officially released a new set of anti-monopoly guidelines aimed at limiting the power of internet platforms. The rules, released on Friday (February 13), are designed to ensure fair competition and prevent platforms from charging unfairly high prices. One of the most significant parts of the new guidelines targets the algorithms of these platforms.","https://static.toiimg.com/thumb/msid-128310062,imgsize-31466,width-400,resizemode-4/china-flag.jpg"
Lenovo Tech World'26 India wraps up with Qira debut and enterprise AI push,https://timesofindia.indiatimes.com/technology/tech-news/lenovo-tech-world26-india-wraps-up-with-qira-debut-and-enterprise-ai-push/articleshow/128307982.cms,"Lenovo unveiled its Qira ambient AI system and enterprise AI strategy in India, showcasing new inferencing servers for businesses. The company emphasized a hybrid AI approach for Indian enterprises, highlighting the nation's tech potential. Lenovo also announced its role as the Official Technology Partner for the FIFA World Cup 2026, promising AI-driven enhancements for stadium operations and fan engagement.","Lenovo unveiled its Qira ambient AI system and enterprise AI strategy in India. The company emphasized a hybrid AI approach for Indian enterprises, highlighting the nation's tech potential. Lenovo also announced its role as the Official Technology Partner for the FIFA World Cup 2026.","https://static.toiimg.com/thumb/msid-128307982,imgsize-106728,width-400,resizemode-4/128307982.jpg"
"1,500 Amazon engineers to company's leadership: Stop forcing us to use your coding tool, we want to‚Ä¶",https://timesofindia.indiatimes.com/technology/tech-news/1500-amazon-engineers-to-companys-leadership-stop-forcing-us-to-use-your-coding-tool-we-want-to/articleshow/128307031.cms,"Amazon engineers are pushing back against a company policy favoring its AI coding assistant, Kiro, over superior third-party tools like Claude Code. Around 1,500 engineers have formally backed Claude Code, citing productivity concerns and questioning how sales teams can promote AWS Bedrock while restricted from using its offerings. This internal dissent highlights a growing demand for better AI tools.","Around 1,500 engineers have formally backed Claude Code. They cite productivity concerns and question how sales teams can promote AWS Bedrock while restricted from using its offerings. This internal dissent highlights a growing demand for better AI tools. It also highlights a company policy favoring its AI coding assistant.","https://static.toiimg.com/thumb/msid-128307031,imgsize-36128,width-400,resizemode-4/128307031.jpg"
What engineers at Spotify really do now as CEO says its developers haven't written a line of code since December,https://timesofindia.indiatimes.com/technology/tech-news/what-engineers-at-spotify-really-do-now-as-ceo-says-its-developers-havent-written-a-line-of-code-since-december/articleshow/128305282.cms,"Spotify's top engineers are no longer writing code, instead directing AI to generate and review it. This shift, powered by an internal system called Honk, has significantly boosted product development, with over 50 new features launched in 2025. Engineers now act as architects and editors, focusing on judgment rather than manual implementation, a move Spotify aims to lead.

Engineers at Spotify are now editors, not coders

Spotify founder Daniel Ek has been warming up to AI for years

Spotify's top engineers have stopped writing code entirely‚Äìand the company isn't worried. In fact, it's celebrating the shift as a sign of where software development is headed. During the company's Q4 2025 earnings call, co-CEO and CTO Gustav S√∂derstr√∂m dropped a striking claim: Spotify's most senior developers haven't manually written a single line of code since December. Instead, they now describe what they want built, let AI generate the code, and then review the output. It's a fundamental change in how one of the world's biggest tech-driven music platforms operates behind the scenes. ""They actually only generate code and supervise it,"" S√∂derstr√∂m told analysts.The shift is powered by an internal system called Honk, which lets engineers request code changes through Slack using Anthropic's Claude Code. The workflow is surprisingly casual‚Äîan engineer on their morning commute can ask Claude to fix a bug in the iOS app, receive a working build on their phone, and merge it to production before reaching the office.Spotify says the system has boosted product velocity significantly. The company shipped over 50 new features throughout 2025, with recent launches including AI-powered Prompted Playlists, Page Match for audiobooks, and About This Song.The real change isn't just about speed‚Äîit's about what engineers actually spend their time doing. According to S√∂derstr√∂m, the bottleneck in software development has shifted from coding capacity to human judgment. Engineers now function more as architects and editors, deciding what should be built rather than physically building it.Think of it as moving from bricklayer to building inspector‚Äîexcept the inspector also picks the blueprint.Spotify began preparing for this roughly 18 months ago by rebuilding its internal systems for what it calls an ""AI-native development environment."" The bet was that software development would eventually be driven by prompting and orchestration rather than manual implementation.Founder Daniel Ek's comfort with AI isn't new. Back in 2023, he called the technology ""huge for creativity"" and resisted calls to ban AI-generated music from the platform. He's consistently argued that AI should enhance human creativity rather than replace it, while acknowledging the murkier questions around voice cloning and artist consent.S√∂derstr√∂m made Spotify's current ambitions clear: ""We are absolutely hell-bent on leading that change.""","Engineers at Spotify are now editors, not coders. Spotify's top engineers are no longer writing code, instead directing AI to generate and review it. This shift, powered by an internal system called Honk, has significantly boosted product development, with over 50 new features launched in 2025.","https://static.toiimg.com/thumb/msid-128305282,imgsize-740644,width-400,resizemode-4/128305282.jpg"
"Tech layoffs in first 40 days of 2026: Amazon, Salesforce, and 25 other companies cut nearly 30,000 jobs",https://timesofindia.indiatimes.com/technology/tech-news/tech-layoffs-in-first-40-days-of-2026-amazon-salesforce-and-25-other-companies-cut-nearly-30000-jobs/articleshow/128305396.cms,"Amazon cut 16,000 jobs

Amazon Launches Largest Layoff Drive Yet, Cutting 30,000 Corporate Positions to Boost Efficiency

Salesforce quietly lays off nearly 1,000 employees

Meta layoffs 1,500 staff

Other tech companies that announced job cuts

Company Date (2026) Roles cut Glossier Feb 11 50 Salesforce Feb 9 Neartly 1,000 Workday Feb 4 400 Smartsheet Feb 4 Not specified Zillow Feb 2 200 Zipcar Feb 2 126 Expedia Feb 1 100 Zupee Jan 30 200 Peloton Jan 30 Not specified Kiwi.com Jan 29 250 Amazon Jan 28 16,000 ASML Jan 28 1,700 Pinterest Jan 27 700 Expedia Jan 27 Not specified Entropy Jan 25 Not specified Autodesk Jan 22 1,000 Shopify Jan 22 Not specified Vimeo Jan 21 Not specified Polygon Jan 16 60 Ericsson Jan 15 1,600 Tipalti Jan 15 100 Playtika Jan 14 500 Aleph Alpha Jan 14 50 Meta Jan 13 1,500 eToro Jan 13 105 StoreDot Jan 13 Not specified MercadoLibre Jan 12 116

We are in the middle of the second month of 2026 and nearly 30,000 jobs have been cut across the global tech sector in the first 40 days of the year. Online retail giant Amazon accounted for the single largest layoff in 2026 after the company announced to cut about 16,000 roles in late January. According to Layoffs.fyi, 26 other major companies that announced workforce reductions include Salesforce, Meta, Workday, Autodesk, Pinterest, Expedia, Zillow, Ericsson, and ASML. Several firms reduced headcount by hundreds of employees, while smaller companies carried out more limited cuts. Here‚Äôs a look at some of the biggest tech layoffs announced so far in 2026, based on data compiled by Layoffs.fyi.Amazon said in January that it is laying off 16,000 employees globally, marking the company‚Äôs second biggest job cut after October last year when it laid off 14,000 roles.Announcing the job cuts, HR chief Beth Galetti said in a memo that teams that didn't finish restructuring in October have now completed the process. She promised this won't become a recurring pattern, but added that adjustments will continue ""in a world that's changing faster than ever.""A Business Insider report recently said that Salesforce has cut nearly 1,000 jobs. Impacted teams include marketing, product management, data analytics, and Salesforce's Agentforce AI product that the company's CEO Marc Benioff has previously said ‚Äúis part and parcel of Salesforce‚Äù.The report said that many of the laid off employees as part of Salesforce job cuts shared on LinkedIn that their roles had been eliminated. At least nine posts reviewed showed job losses across different teams, it says, adding two employees also confirmed the layoffs while speaking to the publication.Earlier this month, Meta announced to reduce its workforce by around 1,500 employees. In an email (seen by the Silicon Valley Business Journal), a Meta spokesperson said, ‚ÄúWe said last month that we were shifting some of our investment from metaverse toward wearables. This is part of that effort, and we plan to reinvest the savings to support the growth of wearables this year.‚ÄùThe job cuts come as the company shifts investment from its metaverse division to wearable technology.Apart from Amazon and Salesforce, several other major technology companies reported layoffs in the first 40 days of 2026, according to data compiled by Layoffs.fyi. Cloud-based HR and finance software provider Workday has cut about 400 jobs, while Autodesk announced layoffs affecting roughly 1,000 roles. Pinterest, on the other hand, has cut about 700 jobs during the same period.In the travel and consumer internet space, Expedia carried out two rounds of layoffs, cutting a combined 200 jobs, while Zillow reduced its headcount by around 200 employees. Peloton announced job cuts affecting about 11% of its workforce, and Vimeo also reported layoffs.ASML cut around 1,700 jobs in the Netherlands, Ericsson reduced about 1,600 roles in Sweden, and Germany-based AI company Aleph Alpha cut around 50 jobs. In Israel, Playtika announced layoffs affecting about 500 employees, while eToro and StoreDot also reported job cuts.Smaller startups and crypto firms were not spared. Companies such as Entropy and Polygon reported workforce reductions, indicating that the impact of layoffs extended across company sizes, funding stages, and sectors early in 2026.","Nearly 30,000 jobs have been cut across the global tech sector in the first 40 days of 2026. Salesforce, Meta, Workday, Autodesk, Pinterest, Expedia, Zillow, Ericsson, and ASML are among the companies that announced job cuts. Online retail giant Amazon accounted for the single largest layoff in 2026 after the company announced to cut about 16,000 roles in late January.","https://static.toiimg.com/thumb/msid-128305462,imgsize-481232,width-400,resizemode-4/tech-job-cuts.jpg"
"Quote of the day by Tim Cook: ‚ÄúIt‚Äôs about finding your values, and committing to them. It‚Äôs about finding your North Star. It‚Äôs about making choices. Some are easy. Some are hard. And some will make y",https://timesofindia.indiatimes.com/technology/tech-news/quote-of-the-day-by-tim-cook-its-about-finding-your-values-and-committing-to-them-its-about-finding-your-north-star-its-about-making-choices-some-are-easy-some-are-hard-and-some-will-make-you-question-everything-/articleshow/128303373.cms,"Apple CEO Tim Cook

Quote of the day by Tim Cook



‚ÄúIt‚Äôs about finding your values, and committing to them. It‚Äôs about finding your North Star. It‚Äôs about making choices. Some are easy. Some are hard. And some will make you question everything.‚Äù

Understanding the meaning of the quote by Apple CEO Tim Cook



How Tim Cook‚Äôs leadership reflects this thinking



How to apply Tim Cook‚Äôs quote in daily life



First, knowing your own values can help you make decisions every day. Values give you a clear guide when you need to make decisions about your career, deal with problems at work, or manage your relationships.

Second, sticking to those values means being consistent, even when things get tough. This might mean turning down chances that go against your personal beliefs or standing firm when things get tough.

Third, knowing that doubt is a normal part of growth can help you make decisions. Doubting your choices doesn't mean you've failed. It often means that you are learning and thinking about what you have learned.

Why Tim Cook‚Äôs words continue to resonate



Other famous quotes by Tim Cook



‚ÄúLet your joy be in your journey, not in some distant goal.‚Äù

‚ÄúLife is fragile. We‚Äôre not guaranteed a tomorrow, so give it everything you‚Äôve got.‚Äù

‚ÄúWe see that privacy is a fundamental human right that people have. We are going to do everything that we can to help maintain that trust.‚Äù

""Some people see innovation as change, but we have never really seen it like that. It‚Äôs making things better.""

In a world where decisions need to be made quickly, things change all the time, and there is more and more pressure to succeed, clear values are often what makes a good leader. Tim Cook, the CEO of Apple, has said many times how important it is to stay grounded, especially when you're in charge of one of the world's most powerful tech companies. One of the things he said that made me think the most was about how to make decisions and where to go in life. In this quote, Cook talks about values, commitment, and what he calls a ""North Star,"" which is a guiding principle that helps people stay on track when things get tough.Steve Jobs died in 2011, and Tim Cook became Apple's CEO. Since then, Apple has grown its business in hardware, software, services, and efforts to be more environmentally friendly. Since Cook took over, the company has made privacy, accessibility, environmental responsibility, and ethical supply chains clear priorities. His quote shows this broader view of leadership, where choices aren't just about growth but also about how they will affect things in the long run.The quote points out a truth that many people deal with, whether at work or in their personal lives. Some choices seem easy. Some bring doubt.Some may even make people question what they believe. Cook's message stresses the need to know what your values are before you face these kinds of situations. He says that instead of reacting to trends or pressure, we should make decisions based on principles that stay the same over time.Tim Cook talks about values when he talks about the beliefs and rules that govern behaviour. When things get tough, these values can help you figure things out. People often use the phrase ""North Star"" to mean a constant guide that helps them stay on track, even when things change.The quote also says that not all choices are the same. Some choices are easy to make and don't have much risk. Some people need to make decisions, take responsibility, and deal with the consequences. Cook's words show that sometimes you have to make hard choices, even if they are hard to make. You might start to doubt yourself or your confidence. But having clear values helps people steadily get through these times.The quote says that instead of avoiding hard decisions, you should face them with honesty and purpose. It shows a style of leadership where giving orders is more important than making things easy.Cook has made decisions that are in line with the values he often talks about in public during his time at Apple. One example is that Apple has always been very clear about how important user privacy is to them, even when it meant going against what other people wanted. The company's investments in renewable energy and efforts to cut down on carbon emissions also show that they are committed to the long term, not just the short term.In speeches and interviews, Cook has said that being a leader means making decisions that aren't always popular but are necessary. His quote is like these actions, showing that he does what he says he will do.You can use the ideas in this quote in more than just business or leadership roles.People can make choices that feel more meaningful and stable over time if they focus on the long term instead of the short term.People often pay attention to what Tim Cook says because he connects leadership to personal responsibility. He doesn't just talk about success; he also talks about values, direction, and being careful when you take action. His words help us think about how to make choices in a world where people are always making them.The quote reminds us that we should not seek approval from others to find clarity. This is done by focusing on values and dedication. It stresses that knowing what really matters is the first step to real progress in your personal or professional life.Tim Cook has shared several statements that reflect his views on leadership, responsibility, and purpose. Some of his widely quoted remarks include:","Tim Cook, the CEO of Apple, has said many times how important it is to stay grounded, especially when you're in charge of one of the world's most powerful tech companies. In this quote, Cook talks about values, commitment, and what he calls a ""North Star,"" which is a guiding principle that helps people stay on track.","https://static.toiimg.com/thumb/msid-128303562,imgsize-25772,width-400,resizemode-4/apple-ceo-tim-cook.jpg"
"Google AI CEO Demis Hassabis makes a huge AI prediction for humanity and it is not that it will take all your jobs, but that it will improve ...",https://timesofindia.indiatimes.com/technology/tech-news/google-ai-ceo-demis-hassabis-makes-a-huge-ai-prediction-for-humanity-and-it-is-not-that-it-will-take-all-your-jobs-but-that-it-will-improve-/articleshow/128301723.cms,"Google DeepMind CEO Demis Hassabis on his sleep routine

Google DeepMind CEO Demis Hassabis has said that one of the most important uses of artificial intelligence (AI) will be improving human health. In a post shared on X (formerly Twitter), Hassabis said AI is already helping speed up drug discovery and could change how new medicines are developed at Isomorphic Labs that he co-founded in 2021. His comments come amid wider debate over AI‚Äôs impact on jobs and automation, with Hassabis highlighting healthcare as a key area where AI could deliver long-term benefits for humanity.‚ÄúOne of the most important things we can use AI for is to improve human health,‚Äù Hassabis wrote in an X post.‚ÄúA biotech startup might do one or two drugs its entire corporate life,‚Äù Hassabis told Fortune. ‚ÄúBut we‚Äôre trying to build a system, a process, and all the technology to do maybe dozens of drugs each year. That seems crazy right now, but I think eventually, over the next 10 to 20 years, we could get to finding a solution to all disease‚Ä¶if we have a process that can find these needles in a haystack.‚ÄùFor those unaware, Isomorphic Labs is a Google-backed company that focuses on using AI to support the discovery and design of new medicines. Hassabis said the work aims to improve how quickly treatments move from research to development, with the goal of improving outcomes for patients worldwide.During the same interview, Demis Hassabis admitted that his sleep routine is far from typical. Hassabis revealed that he sleeps ‚Äòvery little‚Äô aiming for about six houses and added that he divides his waking hours into two distinct workdays. ‚ÄúI do try and get six, but I have unusual sleeping habits. I sort of manage during the day,‚Äù he explained. Hassabis added that his schedule includes packing his office hours with back-to-back meetings, then returning home for family time and dinner.Around 10 pm, Hassabis begins what he calls a ‚Äòsecond day of work‚Äô, often continuing until 4 am. This late-night block is reserved for creative thinking and research. ‚ÄúI can‚Äôt imagine being creative at four in the morning. But, I come alive at about 1 a.m.,‚Äù he told Fortune.",Google DeepMind CEO Demis Hassabis says one of the most important uses of artificial intelligence (AI) will be improving human health. Hassabis said AI is already helping speed up drug discovery and could change how new medicines are developed at Isomorphic Labs that he co-founded.,"https://static.toiimg.com/thumb/msid-128301688,imgsize-30694,width-400,resizemode-4/google-ai-ceo-demis-hassabis.jpg"
"Cisco president Jeetu Patel makes it clear, says: We will not have developers at Cisco who‚Ä¶",https://timesofindia.indiatimes.com/technology/tech-news/cisco-president-jeetu-patel-makes-it-clear-says-we-will-not-have-developers-at-cisco-who/articleshow/128301416.cms,"Cisco's president Jeetu Patel mandates AI for all developers, aiming for half a dozen AI-coded products by 2026. This shift to spec-driven development sees human teams shrink, with AI agents tripling output. While embracing AI's potential, Cisco is investing heavily in security to prevent rogue agents, urging developers to master AI to stay relevant.

Fewer humans, more AI agents, and triple the output

'Background checks' for AI agents that could go rogue

Cisco's president Jeetu Patel has sent a strong signal about where the company is headed‚ÄîAI won't be optional for its developers, it'll be the baseline. Speaking to Euronews Next at an AI Summit in Amsterdam, Patel revealed that Cisco has already built its first product using 100 percent AI-generated code, with no human-written lines in the mix. By the end of 2026, he expects at least half a dozen more products to follow the same path.""We won't have developers at Cisco who don't choose AI as a core habit,"" Patel said. ""Don't worry about AI taking your job, but worry about someone using AI better than you definitely taking your job.""The shift isn't just philosophical. Cisco says it's moving from traditional agile development to what it calls spec-driven development, a model where a team of eight humans shrinks to three, with five AI agents filling in. The result, according to Patel, is triple the output.These AI agents aren't simple autocomplete tools. Cisco envisions them as digital co-workers that plan tasks, solve problems, and operate with minimal human oversight. Patel even pushed back on the popular ""human-in-the-loop"" framing, arguing the mindset should flip to ""AI is in every loop.""That said, human coders still have a role‚Äîthey'll be the ones reviewing what the AI writes.Patel wasn't all optimism, though. He flagged AI safety as something that keeps him up at night, comparing the onboarding of AI agents to hiring employees.""These agents need to get the background checks done, just like you get a background check done for an employee,"" he said.Cisco is investing billions in security infrastructure to tackle two sides of the same coin‚Äîprotecting AI agents from external attacks, and protecting the world from agents that ""go rogue.""His advice to developers worried about job security? ""Don't worry about AI taking your job, but worry about someone using AI better than you definitely taking your job,"" Huang said.",Cisco's president Jeetu Patel says AI won't be optional for its developers. The company has already built its first product using 100 percent AI-generated code. Patel expects at least half a dozen more products to follow the same path by 2026.,"https://static.toiimg.com/thumb/msid-128301416,imgsize-43940,width-400,resizemode-4/128301416.jpg"
Donald Trump is angry with Apple; warns iPhone-maker: Make sure you do not violate American laws by‚Ä¶,https://timesofindia.indiatimes.com/technology/tech-news/donald-trump-is-angry-with-apple-warns-iphone-maker-make-sure-you-do-not-violate-american-laws-by/articleshow/128299015.cms,"The Trump administration has accused Apple's News app of bias, alleging it sidelines conservative media. FTC Chairman Andrew Ferguson warned Apple CEO Tim Cook that such curation could violate federal law by misleading users. A report cited by the FTC found no right-leaning outlets among top stories.

FTC says Apple News curation could violate consumer protection laws

Apple's careful balancing act with the Trump administration gets trickier

The Trump administration has fired a warning shot at Apple over its popular News app, accusing the iPhone maker of quietly sidelining conservative media outlets while pushing articles from left-leaning publications. Federal Trade Commission Chairman Andrew Ferguson, a Trump appointee, sent a letter to Apple CEO Tim Cook raising concerns that Apple News may be violating federal law by misleading users about how it curates content.Ferguson's letter pointed to a report by the Media Research Center, a conservative media watchdog, which reviewed 620 top stories featured on Apple News during January. According to the report, not a single article came from a right-leaning outlet. Instead, publications like The Associated Press, NBC News, The New York Times, and The Washington Post dominated the feed. Conservative outlets such as Fox News, the New York Post, and the Daily Wire were nowhere to be found.""I abhor and condemn any attempt to censor content for ideological reasons,"" Ferguson wrote, adding that such efforts ""stifle the free exchange of ideas"" and are ""inconsistent with American values.""Ferguson was careful to note that the FTC cannot force Apple to promote any particular political viewpoint. However, he warned that if Apple's content curation doesn't match what its terms of service promise‚Äîor what users reasonably expect‚Äîthe company could be in violation of the FTC Act, which prohibits deceptive business practices.FCC Chairman Brendan Carr, another Trump appointee, backed Ferguson's stance, posting on X that Apple ""has no right to suppress conservative viewpoints in violation of the FTC Act.""Trump himself had shared the Media Research Center report on Truth Social just a day before Ferguson sent his letter.The warning comes at an awkward time for Apple. Tim Cook has worked hard to maintain a working relationship with the Trump White House, pledging over $600 billion in US investments over the next four years. The company also managed to dodge aggressive tariffs on imported smartphones.But the goodwill took a hit this week after Apple sponsored the Super Bowl halftime show featuring Puerto Rican artist Bad Bunny. Trump called the performance ""absolutely terrible, one of the worst, EVER"" and ""a slap in the face to our country,"" in a Truth Social post.",FTC says Apple News curation could violate consumer protection laws. Report cited by FTC found no right-leaning outlets among top stories. FTC Chairman Andrew Ferguson warned Apple CEO Tim Cook that such curations could violate federal law by misleading users.,"https://static.toiimg.com/thumb/msid-128299015,imgsize-1215808,width-400,resizemode-4/128299015.jpg"
India‚Äôs AI choices at the 2026 AI Impact Summit amid structural drifts in global markets,https://timesofindia.indiatimes.com/technology/tech-news/indias-ai-choices-at-the-2026-ai-impact-summit-amid-structural-drifts-in-global-markets/articleshow/128298538.cms,"'Biggest AI Summit': Ashwini Vaishnaw Says India AI Impact Summit Getting 'Phenomenal Response'

Preparing for Global AI Markets Undergoing Structural Drifts



The Purpose of Technoeconomic Hedging for Indian AI Ecosystems



Building a Grounded AI Safety Research Agenda



By: Abhivardhan President, Indian Society of Artificial Intelligence and Law Founder,

Indic Pacific Legal

Research

And

Deepanshu Singh

, Distinguished Expert of the Advisory Council, Indian Society of Artificial Intelligence and Law, Senior Programme Manager, GATI Foundation

As we approach the AI Impact Summit 2026, global AI exosystems are undergoing a brutal yet necessary recalibration. Those calibrations are driven by the realisation that current AI systems, especially large language models, are powerful pattern recognisers but still brittle tools when treated as general problem solvers rather than as narrowly scoped components in wider systems.The strategic implications of generative AI systems have generated competing visions across scientific, policy, and commercial communities since their widespread adoption began in the early 2020s. The technical breakthroughs in large language and vision models during early 2023‚Äîaccompanied by advances in data processing and computational architectures‚Äîcreated narratives of transformative potential across economic sectors. Yet, these models have not resolved long‚Äëstanding issues around reasoning and causal understanding that classical AI researchers have highlighted for years.Yet the semiconductor rivalry and Taiwan‚Äëfocused supply constraints exposed how an LLM‚Äëcentric view of AI had become strategically narrow for countries like India. If India‚Äôs AI policy anchors itself only on scaling bigger neural networks hosted abroad, it risks deep technological dependence without acquiring robust capabilities in data engineering, evaluation, and alternative architectures.This article therefore proposes that it is high time that India pursues a unique form of technoeconomic strategic hedging, as its key economic diplomacy deliberations as part of the AI Impact Summit 2026 would undergo from next week. Such hedging should explicitly diversify across AI paradigms‚Äîclassical machine learning, optimisation, hybrid neuro‚Äësymbolic systems, and domain‚Äëspecific models‚Äîrather than implicitly narrowing national AI priorities to the single dimension of ever‚Äëlarger LLMs.History has witnessed cycles of hype across sectors, domains and other facets of human life. Some hype cycles represent genuine technological progress and justified enthusiasm, while others reflect market dynamics and technically unsound practices designed primarily to extract capital rather than deliver durable value. The current AI landscape leans towards the latter pattern in important respects: large language models are frequently marketed as general reasoning engines, even though they remain pattern recognisers with persistent limitations in robustness and verifiability.When market concentration allows a handful of actors to control both the technology narrative and the infrastructure supporting it, nations face strategic vulnerability to hype‚Äëdriven investment cycles that may not align with their development priorities. This vulnerability becomes evident when new model announcements trigger sharp stock‚Äëmarket reactions, as seen in market moves linked to DeepSeek releases in January 2025 and subsequent launches of advanced coding models in early February 2026: in each case, expectations about sudden disruption outpaced any clear evidence of stable, production‚Äëgrade value creation. For countries like India, these episodes are instructive not as warnings against innovation, but as reminders that market perception around ‚Äúfrontier AI‚Äù can move much faster than the underlying capability to solve concrete problems reliably. This mismatch is nevertheless unsurprising. If organisations do not clearly define the problem, the data and the metric for success, no frontier model will consistently deliver value beyond demonstrations. At the same time, long‚Äëstanding critiques from classical AI and cognitive science highlight that simply scaling current architectures is unlikely to produce strong compositional reasoning or robust understanding.Taken together, these perspectives suggest that technoeconomic strategic hedging should not be about rejecting large models, but about placing them in a broader portfolio of approaches suited to specific domains and constraints that can be engineered, evaluated and governed in line with sector‚Äëspecific needs.In such a setting, India‚Äôs strategic question is not whether to participate in the global LLM ecosystem, but how to avoid narrowing its AI ambitions to a single class of models whose market narratives can overshadow their technical constraints. Preparing for structural drifts in global AI markets means investing in data quality, evaluation culture, and diverse architectures, so that India can absorb the benefits of frontier systems where they genuinely help, while maintaining the autonomy to build, deploy, and scrutinise its own AI systems across critical domains.Strategic autonomy without matching domestic capability in software, chips, engines and energy leads to continued dependency. In the AI context, this highlights a basic distinction between merely consuming externally built models and infrastructure, and developing capacity across data, architectures and deployment practices within the country.India is perhaps the most democratic and exploited testbed of data for the rest of the world, and hence a very democratised data and consumer market. A large share of global AI systems are trained, fine‚Äëtuned or evaluated on behaviours, languages and environments that include Indian data, yet the modelling, evaluation and deployment capabilities often reside elsewhere. However, India is also a significant beneficiary of the digital nomad economy, which even China cannot replicate due to state‚Äëled data‚Äëoutflow and ownership laws, despite its achievements with DeepSeek (whose founder ran a quantitative hedge fund, High‚ÄëFlyer, where he developed and used AI for stock‚Äëmarket trading strategies). This combination means that India can support data localisation where it chooses‚Äîthrough local storage, processing and governance‚Äîwithout cutting itself off from global AI collaboration and markets. Converting this data position into durable technical advantage requires investing not just in compute, but in data pipelines, labelling infrastructure, sectoral benchmarks and engineering practices that allow models to be tested, monitored and updated in production.A true hedge requires betting on what comes after the current wave. We must therefore diversify beyond LLMs into alternative paradigms like neurocompositional methods, symbolic AI and domain‚Äëspecific systems. These architectures allow explicit structure‚Äîrules, knowledge graphs, constraint solvers‚Äîto be combined with learned components, which is valuable where reasoning transparency, auditability and stable generalisation matter more than fluent text generation. These approaches offer protection against LLM saturation and open the door for democratised research. From a practical standpoint, such diversity also reduces the likelihood that a single class of models, with its known failure modes, becomes the bottleneck for critical applications.Perhaps the most radical proposal for the Summit is the ‚ÄúFramework Inversion‚Äù principle, where treating data governance as the primary framework with AI governance as merely a subset is more sensible. Under this inversion, questions of consent, provenance, labelling, access and retention are addressed first; model choices then follow from what is permissible and technically appropriate for specific datasets and tasks. This structure also forces clarity about intended use: if the data cannot be collected, documented and governed for a particular purpose, the model should not be deployed for that purpose, regardless of its general capabilities. If models are volatile, data is the controllable asset. We must prioritise data infrastructure, privacy frameworks and cross‚Äëborder flow management over chasing the latest model architecture. Technically, this means investing in storage, metadata systems, version control for datasets and monitoring pipelines that track data drift and label quality over time.An effective approach to AI safety and governance in India can focus on empirical evidence and clear measurement. This includes building a stronger epistemic basis by systematically collecting and sharing data on model failures, near‚Äëmisses and misuse cases, using transparent methodologies that allow independent inspection and replication. It also involves a multidisciplinary approach with testable hypotheses for each sector, combining computer science, statistics, domain knowledge and legal analysis around specific questions rather than broad, abstract principles. At a basic level, risk needs to be quantified by defining what counts as a material failure, what thresholds are acceptable and how those thresholds map onto limits on deployment, monitoring and escalation. Where AI systems interact with or substitute for human activities, comparisons with human performance should be expressed as concrete limits on when a system may assist, when it requires supervision and when full automation is not appropriate.Educational narratives on AI safety can emphasise epistemic humility, highlighting that current systems are tools with known limitations that must be understood and managed. Stakeholder engagement can be organised in two phases: a research and documentation phase before public communication, followed by a phase focused on perception, business impact and educational needs, given the stochastic nature of AI risk narratives. A simple classification of AI systems by function, autonomy and domain helps avoid over‚Äëgeneralisation from LLM‚Äëcentric debates, while a clear articulation of intended purpose and intended usage‚Äîsupported by discernible product, service, tool and infrastructure categories‚Äîenables verifiable claims and accountability. Examples such as Sahyog Portal and Sanchar Saathi indicate that clearly defined objectives, clean data and modest models, integrated into operational workflows, can produce measurable outcomes without relying on frontier‚Äëscale systems.","As we approach the AI Impact Summit 2026, global AI exosystems are undergoing a brutal yet necessary recalibration. Current AI systems are powerful pattern recognisers but still brittle tools when treated as general problem solvers. If India‚Äôs AI policy anchors itself only on scaling bigger neural networks hosted abroad, it risks deep technological dependence.","https://static.toiimg.com/thumb/msid-47529300,imgsize-110164,width-400,resizemode-4/47529300.jpg"
"Months after CEO Sam Altman called China's DeepSeek R1 model 'impressive', OpenAI sends memo to US government saying Chinese company is 'cheating', it is using ...",https://timesofindia.indiatimes.com/technology/tech-news/months-after-ceo-sam-altman-called-chinas-deepseek-r1-model-impressive-openai-sends-memo-to-us-government-saying-chinese-company-is-cheating-it-is-using-/articleshow/128297107.cms,"Memo that OpenAI sent to US lawmakers

DeepSeek R1 model debuted in January last year. After its launch, OpenAI CEO Sam Altman shared a post on X calling the AI model ‚Äúimpressive‚Äù, adding ‚Äúit's legit invigorating to have a new competitor‚Äù. A year later, the ChatGPT-maker is accusing the Chinese AI model of cheating. In a letter to the US House Select Committee on China, OpenAI accused DeepSeek of ‚Äúfree-riding‚Äù on the capabilities developed by OpenAI and other US frontier to replicate models and use them for its own training. The AI company said that it has observed accounts associated with DeepSeek employees developing methods to circumvent OpenAI‚Äôs access restrictions and access models through obfuscated third-party routers and other ways that mask their source.OpenAI alleges that DeepSeek is using the distillation tactic ‚Äì a technique used to train smaller models using outputs from more advanced systems to copy AI models. Here‚Äôs the memo it sent to the US lawmakersOpenAI believes the best future is one in which we move forward with democratic AI ‚Äì AI that is shaped by the principles America has always stood for. In advancing democratic AI, America is competing with a Chinese Communist Party (CCP) determined to become the global leader in AI by 2030.That‚Äôs one reason why the release of DeepSeek‚Äôs R1 model at the Lunar New Year one year ago was so noteworthy: as a gauge of the state of this competition.In March 2025, in response to this Committee's request, OpenAI provided an assessment of DeepSeek's distillation techniques. In the year since, OpenAI has taken steps to protect and harden our models against distillation. Ahead of DeepSeek‚Äôs expected Lunar New Year release of a new, more powerful model, we are providing the Committee with an updated assessment of its evolving distillation tactics, as well as other gauges of CCP progress toward its 2030 goal, and OpenAI‚Äôs efforts on these fronts to advance American-led, democratic AI.Distillation: DeepSeek‚Äôs next model (whatever its form) should be understood in the context of its ongoing efforts to free-ride on the capabilities developed by OpenAI and other US frontier labs. In this memo, we detail:‚Ä¢ Activity we‚Äôve observed on our platform that is indicative of ongoing attempts by DeepSeek to distill frontier models of OpenAI and other US frontier labs, including through new, obfuscated methods.‚Ä¢ How DeepSeek reflects CCP censorship and control of information in its responses, including examples.‚Ä¢ How China is providing significant state support for its frontier labs and the underlying energy needed to scale compute.‚Ä¢ Steps we have taken in the last year to address adversarial distillation, and areas where further partnership with the US government would be beneficial.Energy: The scarcest resource in AI is compute, i.e., power plus chips. Sustaining the American advantage on AI increasingly depends on whether we can reliably generate and deliver power at scale in order to fulfill our compute needs. New data on the scale of China‚Äôs recent gains in energy generation underscores our ‚Äúelectron gap‚Äù:‚Ä¢ In 2025, China added 543 GW of new power capacity ‚Äì 10X the amount of electricity added by the US, and over 100 GW more than it added in 2024.1‚Ä¢ In 2024, as we recently highlighted, China added 429 GW of new power capacity ‚Äì an amount that was more than one-third of the US grid and more than half of global electricity growth. The United States added 51 GW.‚Ä¢ Since 2021, i.e., in less than five years, China has added more grid capacity than the US has ever built.2OpenAI believes that infrastructure is destiny: chip development, power generation, transmission, and data center capacity will determine which countries can train and deploy frontier systems. This is why we‚Äôre investing through our Stargate Project to expand US AI infrastructure to 10 GW by 2029, and just one year in, we‚Äôre already over halfway toward that goal.Compute: Investment in compute powers research and step-change gains in model capability. For OpenAI, looking on the past three years, our ability to innovate and serve more people ‚Äì the vast majority of our over 800 million regular users use our technology for free ‚Äì has tracked with available compute:‚Ä¢ OpenAI‚Äôs available compute grew 9.5X from 2023 to 2025 (3X year-over-year): 0.2 GW in 2023, 0.6 GW in 2024, and ~1.9 GW in 2025. Revenue followed the same trajectory, growing 3X YoY.‚Ä¢ At the same time, limited compute continues to delay our ability to deliver new, in-demand features.This is unprecedented growth at this scale, and we believe more available compute during this period would have driven even greater innovation and faster adoption. As our Stargate efforts show, we are committed to expanding compute to drive further progress. But we are equally focused on ensuring a level playing field, one where the People‚Äôs Republic of China (PRC) can‚Äôt advance autocratic AI by appropriating and repackaging American innovation.OpenAI believes the best defense is offense: the best way to ward off a fast-oncoming PRC making headway around the world for autocratic AI is continued investment in American AI leadership and global adoption of responsibly developed, democratic AI. We continue to lead in responsible frontier model innovation, invest across the full AI stack to train and deploy our systems safely, and make powerful AI tools available for free. Adoption of our latest agentic coding model, GPT-5.3-Codex, is up 60% week-over-week. Adoption of ChatGPT is at ~10% monthly growth.We stand ready to provide a closed-door briefing to the Committee upon request.What we see from DeepSeek and other Chinese LLM ProvidersAdversarial Distillation AttemptsThe majority of adversarial distillation activity we‚Äôve observed on our platform appears to originate from China, and occasionally from Russia. We have observed usage patterns from several major Chinese LLM providers and some university research lab usage that are consistent with, and would be highly beneficial for, creating competitor models through distillation.Over the past year, we have seen evolving but persistent methods of distillation against our models. We believe these approaches to distillation are changing in part because we have added new methods to protect our models.Specifically, our review indicates that DeepSeek has continued to pursue activities consistent with adversarial distillation targeting OpenAI and other US frontier labs. We have observed accounts associated with DeepSeek employees developing methods to circumvent OpenAI‚Äôs access restrictions and access models through obfuscated third-party routers and other ways that mask their source. We also know that DeepSeek employees developed code to access US AI models and obtain outputs for distillation in programmatic ways. We believe that DeepSeek also uses third-party routers to access frontier models from other US labs.More generally, over the past year, we‚Äôve seen a significant evolution in the broader model-distillation ecosystem. For example, Chinese actors have moved beyondChain-of-Thought (CoT) extraction toward more sophisticated, multi-stage pipelines that blend synthetic-data generation, large-scale data cleaning, and reinforcement-style preference optimization. We have also seen Chinese companies rely on networks of unauthorized resellers of OpenAI‚Äôs services to evade our platform‚Äôs controls. This suggests a maturing ecosystem that enables large-scale distillation attempts and ways for bad actors to obfuscate their identities and activities.It‚Äôs important to note that there are legitimate use cases for distillation: as a technique used to train smaller models using outputs from more advanced systems. OpenAI provides responsible distillation pathways for developers. However, we do not allow our outputs to be used to create imitation frontier AI models that replicate our capabilities.Furthermore, when capabilities are copied through adversarial distillation without the corresponding safety governance and mitigations, the result is cheaper-to-scale systems, where subtle deficiencies may only become obvious after deployment, when failures are hardest to contain. We continue to see signs that DeepSeek models lack meaningful guardrails against dangerous outputs in high-risk domains like chemistry and biology, or offer limited protections for copyrighted material. Despite signing China‚Äôs voluntary ‚ÄúArtificial Intelligence Safety Commitments,‚Äù DeepSeek still has not published a clear safety framework or evidence of robust testing and independent red-teaming, leaving limited visibility into jailbreak resistance, misuse potential, and other high-impact failure modes.Continued Model Censorship and Pro-CCP BiasOur review of DeepSeek‚Äôs behavior indicates that there are overlapping forms of censorship at work, and DeepSeek‚Äôs pro-CCP bias appears to be more severe in recent model releases. This censorship is applied not only within the PRC, but also to global users of DeepSeek‚Äôs product.Censorship is likely being implemented in multiple ways, including both model post-training and the use of monitoring tools or classifiers that review responses for alignment with CCP policy and, where required, delete them after they have been presented to the user. On topics sensitive to the CCP, such as Tiananmen Square or Taiwan independence, DeepSeek frequently issues outright refusals. That form of censorship is trained into the model‚Äôs weights and limits what the model will say regardless of where it is deployed. The model will avoid negative or critical language about the CCP, use positive language about the PRC‚Äôs efforts and achievements and use negative language when discussing the US or the West.Beyond outright refusals, DeepSeek often shows framing and terminology bias, offering more confident, detailed responses for PRC-aligned narratives while deflecting, hedging, or re-centering on Western faults when prompts invite criticism of the CCP.There also appears to be a dynamic layer of censorship in the DeepSeek online chat interface that operates beyond the base model itself. In certain cases, DeepSeek‚Äôs chat initially generates a substantive response to politically sensitive prompts, then freezes, deletes the output, and issues a refusal. This pattern suggests that a secondary monitoring or classification system may be reviewing generated content in real time and suppressing responses that conflict with CCP political requirements. Topics that have been observed in this category include human rights in Xinjiang; sovereignty in the South China Sea; and the role of Winnie the Pooh in online discourse in China. Below is a sample screenshot of content before it was deleted and after:On some occasions, DeepSeek refuses to give an answer that it deems ‚Äúharmful‚Äù. When asked why the question is harmful, it has been observed to explain its ‚Äúsafety principles‚Äù, then delete them. Below are three sample snapshots of a conversation in which DeepSeek was asked about the Falun Gong, refused to answer, and was asked to explain. The response self-deleted immediately after the completion of the word, ‚ÄúFalun‚Äù:State Support for the AI StackDeepSeek operates within a PRC ecosystem that provides structural, state-backed support across the AI stack. At the Fourth Plenum in October 2025, the CCP elevated AI as central to national modernization, reinforcing a strategy backed by large subsidies and coordinated support for national champions. Through industrial policy and preferential procurement, this ecosystem enables DeepSeek to scale rapidly and export low-cost AI infrastructure andCCP-aligned model ecosystems abroad ‚Äì embedding Chinese technical standards and content norms in emerging markets.Amendments to the Cybersecurity Law effective January 1, 2026 further formalize state support for foundational AI research, algorithmic development, and expanded computing and training data infrastructure. The same state-enabled scale that drives commercial competitiveness also strengthens the ability of Chinese AI labs to support the People‚Äôs Liberation Army (PLA) and the PRC‚Äôs public security systems through advanced analytics and decision-support capabilities.What OpenAI Is DoingAdversarial distillation poses serious cost, safety, commercial, and strategic risks to the US. It lowers the barrier to training advanced models by letting adversaries reuse frontier model outputs instead of investing in their own R&D and compute; it can strip away alignment and abuse safeguards, resulting in less secure systems; and by blending outputs from multiple US LLMs, adversaries could replicate and even combine frontier capabilities in ways that surpass any single teacher model.Adding More ProtectionsWe continue to invest in stronger guardrails and detection systems to prevent unauthorized distillation and misuse of model outputs. When we detect circumvention, we take action and reinforce our defenses. As distillation techniques have evolved into more sophisticated, multi-stage pipelines, our approach has shifted from focusing on isolated CoT extraction to addressing the full distillation lifecycle and preventing recidivism across accounts and infrastructure.We proactively remove users who appear to be attempting to distill our models to develop competitive models to OpenAI. Detection relies on layered methods, including heuristics, machine learning, and manual review. To identify reinforcement learning‚Äìstyle grading behavior, we deploy offline and real-time classifiers that monitor ranking and scoring patterns. To flag synthetic data generation, we assess scale and prompt diversity across accounts. To prevent CoT extraction, our models are trained not to reveal reasoning traces, and additional input and output classifiers monitor for likely leakage, including in jailbreak scenarios. We also leverage human and automated investigators to identify activity linked to known adversarial actors.When we identify distillation that violates our terms of service, we take enforcement measures including banning accounts.This multi-layered strategy enables us to adapt as techniques evolve and to disrupt activity across the full account lifecycle, rather than reacting to isolated tactics.Protecting American TechnologyProtecting American technology across the entire AI stack and preventing diversion to the CCP ecosystem is essential to sustaining US leadership. The Trump Administration‚Äôs updated approach to the export of chips to China reflected a clear ‚Äúdomestic-first‚Äù logic. We commend the efforts of US chip suppliers to invest in increasing capacity for US AI labs, and their array of partnerships with such labs to support the further buildout of US AI infrastructure.As we continue to design and develop our own silicon, our focus is also on protecting American technology. For us, this means securely deploying our own chips in the US and in high-trust environments with strong security measures ‚Äì consistent with the approach of our OpenAI for Countries initiative to promote adoption of democratic AI by US allies and partner countries around the world.Advocating for Ecosystem ApproachOpenAI supports an ‚Äúecosystem security‚Äù approach to frontier model distillation protection: it is not enough for any one lab to harden its protection because adversaries will simply default to the least protected provider.While strengthening OpenAI‚Äôs safeguards improves protection on our own platforms, durable risk reduction requires protections across frontier labs, API routers, distributors, and infrastructure providers. A more consistent industry approach reduces the ‚Äúpath of least resistance‚Äù that determined adversaries will otherwise exploit.Specific areas where US government policy may be helpful include:‚Ä¢ Expanding the shared operating picture through intelligence and information sharing.‚Ä¢ Working with industry to establish norms and best practices on distillation defenses.‚Ä¢ Addressing API router loopholes.‚Ä¢ Restricting adversary access to US compute, cloud, payment, and web infrastructure.‚Ä¢ Encouraging allies to adopt comparable standards.Continuing to Invest in Frontier Models and a Broader Safety EcosystemOpenAI continues to lead in frontier model innovation, iterating and scaling capabilities in a responsible manner. We deploy models with safety features that balance innovation with risk mitigation, and we invest across the full AI stack to train and deploy systems safely.Our release of GPT-5.3-Codex, our most capable agentic coding model to date, reflects this approach. In tandem with the release, we are strengthening the cybersecurity ecosystem and deploying our most comprehensive cybersecurity safety stack yet, including dual-use safety training, automated monitoring and detection, and trusted access mechanisms for advanced cyber capabilities.Recent growth signals continued momentum: Codex is up 60% week-over-week to 1.3 million weekly active users, and ChatGPT has returned to ~10% monthly growth. Sustained investment in frontier research is essential to maintaining US advantage. Democratic AI must be broadly accessible, and OpenAI is committed to delivering powerful tools that help individuals, businesses, researchers, and governments innovate responsibly.What more we can do togetherIncrease awareness of PRC free-riding that undermines American competitivenessAs stated above, we assess that Chinese LLMs are actively cutting corners when it comes to safely training and deploying new models. There is an opportunity to impose a reputational cost on Chinese LLMs ‚Äì and the CCP ‚Äì by increasing awareness of how these labs are operating:‚Ä¢ Circumvention of safeguards.‚Ä¢ Access to US model outputs.‚Ä¢ State-backed compute accumulation.‚Ä¢ Regulatory asymmetries.‚Ä¢ Lax pre-deployment safety measures.Revealing how PRC labs operate is essential to informing the public and shaping policy responses.Seize the Generational Opportunity to Invest in the Entire AI StackThe US must invest across the entire AI stack ‚Äì from supercomputers and data centers to advanced semiconductor manufacturing, power generation and transmission, and the talent pipelines that sustain long-term leadership. It should also strengthen public data resources and build secure, scalable pathways for government adoption so democratic institutions can use frontier AI responsibly and effectively. Sustained, strategic investment in compute, infrastructure, and model innovation will determine whether democratic AI prevails in this competition.Global AI Competition: A technological wave with geopolitical consequencesAt its core, this is a contest between democratic and autocratic models of AI. We believe AI should be built on democratic rails: advancing personal freedom, expanding economic opportunity, and embedding safeguards that prevent its use as a tool of state control.Democratic AI means broad access to advanced tools, user agency and literacy, a balance between safety and innovation, and transparency and accountability. Autocratic systems, by contrast, are developed within regimes that mandate censorship, alignment with state narratives, and cooperation with government authorities.As the 2025 National Security Strategy makes clear, technology leadership, resilient supply chains, energy capacity, and industrial strength underpin American security and prosperity. AI has the potential to accelerate discovery, planning, logistics, forecasting, and decision-making across military, economic, and diplomatic domains. The competition spans compute, semiconductors, power generation, talent, model innovation, and government adoption. The advantages will compound for those who integrate the technology and the central question is whether democracies will continue to build and scale ahead of centralized competitors.On the eve of the AI Summit in India, the world‚Äôs largest democracy, we remain confident that open markets, world-class talent, and responsible innovation will sustain democratic leadership. We are committed to working closely with the US government and like-minded partners to protect national security, strengthen technological leadership, and ensure that the future of AI reflects democratic principles.",OpenAI accused DeepSeek of ‚Äúfree-riding‚Äù on capabilities developed by OpenAI and other US frontier to replicate models and use them for its own training. The AI company said that it has observed accounts associated with DeepSeeking employees developing methods to circumvent OpenAI‚Äôs access restrictions.,"https://static.toiimg.com/thumb/msid-128297121,imgsize-15862,width-400,resizemode-4/months-after-ceo-sam-altman-called-china39s-deepseek-r1-model-39impressive39-openai-sends-memo-to-us-government-saying-chinese-company-is-39cheating39-it-is-using-.jpg"
"Google CTO for AI infrastructure on what gives the company edge over not just OpenAI, but also Nvidia: Real secret weapon that we have is ...",https://timesofindia.indiatimes.com/technology/tech-news/google-cto-for-ai-infrastructure-on-what-gives-the-company-edge-over-not-just-openai-but-also-nvidia-real-secret-weapon-that-we-have-is-/articleshow/128295145.cms,"Google plans data centers in space



Google Chief Technologist for AI Infrastructure recently said that the company‚Äôs main advantage in the AI race lies in how it builds and runs technology across the entire stack, from chips to software. Speaking at the Cisco AI Summit in San Francisco, Amin Vahdat said Google‚Äôs ability to co-design hardware, models, and infrastructure internally allows it to move faster than rivals. ‚ÄúThe real secret weapon that we have is that we get to work together across the stack at the company to solve the end problem,‚Äù Vahdat explained, adding ‚ÄúIf you look at TPUs, they're not designed in isolation. They're co-designed with DeepMind, but also taking input from all of the different use cases: search, ads, YouTube, Cloud.‚ÄùHis remarks come as competition intensifies with companies such as OpenAI and Nvidia, and as AI capabilities improve at a pace that Vahdat said now exceeds traditional computing trends.‚ÄúThings feel like they're getting twice as good, even faster than Moore's Law,‚Äù Vahdat said. ""At this point, I don't see any slowdown,‚Äù he stated.During the summit, Vahdat also discussed Google's moonshot to build AI data centers in orbit.Announced in November 2025, Project Suncatcher is aimed at harnessing sun's energy directly in space.‚ÄúFrom a first principles perspective, it holds a lot of appeal,‚Äù Vahdat said. ‚ÄúA sun-synchronous orbit with 24/7 solar power‚Äîno batteries needed, no cloud cover, no sunset. Networking in space gets you a 50% reduction in latency for speed of light, not having to go through fibers.‚ÄùVahdat‚Äôs comments followed the launch of Google‚Äôs Gemini 3 model, which posted strong results across several AI benchmarks. He said the model‚Äôs performance supports Google‚Äôs long-term strategy of investing in its own models, chips, and data centres.‚ÄúGemini 3 has been awesome. We've been on this three-plus year journey at Google. I'm always rooting for the underdog, and it was great to be at a place where Google was the underdog,‚Äù he said on the new AI model.","Amin Vahdat, Google's Chief Technologist for AI Infrastructure, spoke at the Cisco AI Summit in San Francisco. He said Google's ability to co-design hardware, models, and infrastructure internally allows it to move faster than rivals. He also discussed Google's moonshot to build AI data centers in orbit.","https://static.toiimg.com/thumb/msid-128295133,imgsize-21234,width-400,resizemode-4/google-cto-for-ai-infrastructure-on-what-gives-the-company-edge-over-not-just-openai-but-also-nvidia-real-secret-weapon-that-we-have-is-.jpg"
"David Magerman, the American computer scientist who called OpenAI a Ponzi scheme, writes a long post on AI that says: Please, please don‚Äôt ‚Ä¶",https://timesofindia.indiatimes.com/technology/tech-news/david-magerman-the-american-computer-scientist-who-called-openai-a-ponzi-scheme-writes-a-long-post-on-ai-that-says-please-please-dont-/articleshow/128292420.cms,"Here's what can be called a ‚Äòcomforting post‚Äô from David Magerman

American Computer Scientist David Magerman has a message for almost everyone on artificial intelligence (AI) or rather the AI doomsday prediction. David has been at the forefront of computer science since the 80s and throughout his career has been deeply involved in early efforts to apply machine learning and data analysis technologies to capital markets investing. Magerman is the man who helped build the trading systems of Renaissance Technologies, widely recognized as the best quantitative hedge fund management company in the world. Magerman holds a PhD in Computer Science from Stanford University where his thesis on Natural Language Parsing as Statistical Pattern Recognition was an early and successful attempt to use large-scale data to produce fully-automated syntactic analysis of text.Presently, David Magerman is managing partner and co-founder at Differential Ventures, an early-stage fund that invests in data-focused entrepreneurs building enterprise technology. Magerman is among the scientists who can be said to buck the consensus on AI. In a podcast, earlier his year Magerman said that AI is a machine gun we are giving to kids and definitely a bubble. He is also no fan of Sam Altman's OpenAI , in the same podcast, Magerman said, ""OpenAI isn't a a functioning business.The business model is so demonstrably a Ponzi scheme..."" In a recent long note on LinkedIn, titled ‚ÄòSomething Big is Not Happening', Magerman writes why all the forecasts about AI taking over all humanity is wrong. He says, ‚ÄúPlease, please, please don't take this essay too seriously. Don't believe hype. Look at facts.""There is a dramatic, viral, largely AI-generated essay going around, claiming we are already in the midst of some apocalyptic age where AI is going to transform humanity in some irreparable and harmful way. Please, please, please don't take this essay too seriously. Don't believe hype. Look at facts.LLM-based generative AI solutions are still barely being used in production environments at scale. Most use of LLM-based AI in major corporations is in limited pilots and non-mission-critical internal tasks. And most of the pilots are failing.There are fantastical reports of LLM-based AI solutions doing unbelievably sophisticated things. Many of them are easily debunked (see moltbook). Some are not so easily debunked, but they are also unreproduceable and unproven.Code-generation is one of the most effective use of LLM-based AI, mostly because LLMs are incredibly good at memorizing their training data, and the open-source community has contributed coding solutions to a broad class of problems, and those solutions were used as training data for LLMs (arguably against the license agreements of the code, at least in spirit). But it is unclear how well LLMs can solve new and complex problems. Unproven anecdotes from conflicted parties are not clear evidence.A lot of rich people and valuable, powerful companies have a lot at stake on everyone continuing to believe that LLMs are at the center of a new world order that will transform EVERYTHING. As a manager of a data-focused venture capital fund, I would benefit a lot from this fictional future as well. But it's just that: fiction.Transformer models are a generational scientific improvement in pattern recognition and machine learning which will have long-lasting implications in how humans use computers to translate data into better decision-making. But that's it. Don't get me wrong: that's a lot. But that's it. Everything else is just marketing hype meant to preserve bubble valuations until the major stakeholders in AI-focused companies can figure out how to maintain some of their value or get out before their investors do.Consider the source of everything you read about AI (including this note) before believing it. Try to find as much objective facts as you can about how AI is really being used in the real world, and judge it based on scaled solutions, not anecdotal usage and unverified screenshots of outlandish representations of the supposed power and intelligence of these systems. Presume everyone on the internet is trying to sell you something, and make sure you have enough objective evidence before you buy it.Caveat emptor.","American Computer Scientist David Magerman has a message for almost everyone on artificial intelligence (AI) or rather the AI doomsday prediction. Magerman is among the scientists who can be said to buck the consensus on AI. In a recent long note on LinkedIn, titled ‚ÄòSomething Big is Not Happening', Magerman writes why all the forecasts about AI taking over all humanity is wrong.","https://static.toiimg.com/thumb/msid-128292400,imgsize-6694,width-400,resizemode-4/openai.jpg"
"Microsoft AI CEO Mustafa Suleyman predicts White collar job automation within 18 months, says: AI agents will be able to ...",https://timesofindia.indiatimes.com/technology/tech-news/microsoft-ai-ceo-mustafa-suleyman-predicts-white-collar-job-automation-within-18-months-says-ai-agents-will-be-able-to-/articleshow/128291088.cms,"Mustafa Suleyman on white-collar work and AI automation

Satya Nadella Recounts 2023 Story Of Indian Farmer Leveraging AI Bot For Subsidies

Microsoft‚Äôs push for AI self-sufficiency

Anthropic CEO says software engineering will become obsolete

Mustafa Suleyman, CEO of Microsoft AI has made a bold prediction saying that many white-collar jobs could be automated within the next 12 to 18 months as artificial intelligence (AI) systems become more capable, reports Financial Times. Suleyman said rapid advances in AI could change how professional work is done across sectors such as law, accounting, marketing, and project management. The remarks add to growing debate among technology leaders about AI‚Äôs impact on employment and enterprise workflows. Recently, Anthropic CEO Dario Amodei claimed that software engineering as a profession will become obsolete in 12 months.Microsoft AI CEO Mustafa Suleyman said the company is developing what he described as ‚Äúprofessional grade AGI,‚Äù referring to AI systems designed to handle everyday tasks performed by knowledge workers. He said many office-based roles that involve working on computers could see a large share of their tasks automated within the next 12 to 18 months.He further added that AI agents are expected to improve their ability to coordinate across large organisations over the next two to three years, learning from experience and taking more autonomous actions.As per the report, Suleyman said Microsoft is pursuing ‚Äútrue self-sufficiency‚Äù in AI following a restructuring of its relationship with OpenAI last year.While Microsoft retains access to OpenAI‚Äôs advanced models, it is now building its own foundation models using large-scale computing infrastructure and internal AI teams. The company plans to launch its in-house models later this year and is increasing investment in data, chips, and data centres to support long-term AI development.Speaking at World Economic Forum 2026 last month, Anthropic CEO Dario Amodei said that software engineering will become outdated in the next 12 months.Amodei argues that the ‚Äúpace of progress‚Äù is the defining factor that makes AI more dangerous to the workforce than the fact that it will lead to some job cuts. To support his claim, he pointed out that in just two years, AI has evolved from struggling with a single line of code to writing entire programs for engineers at his own firm.‚ÄúThe pace of progress in AI is much faster than for previous technological revolutions. For example, in the last 2 years, AI models went from barely being able to complete a single line of code, to writing all or almost all of the code for some people‚Äîincluding engineers at Anthropic.37 Soon, they may do the entire task of a software engineer end to end,‚Äù Amodei wrote in a 20,000-word essay last month.","Mustafa Suleyman, CEO of Microsoft AI has made a bold prediction saying that many white-collar jobs could be automated within the next 12 to 18 months. He said rapid advances in AI could change how professional work is done across sectors such as law, accounting, marketing, and project management.","https://static.toiimg.com/thumb/msid-128291074,imgsize-28544,width-400,resizemode-4/microsoft-ai-ceo-mustafa-suleyman.jpg"
Apple 6th Store: Apple to open its sixth store in Borivali on February 26,https://timesofindia.indiatimes.com/technology/tech-news/apple-to-open-its-sixth-store-in-borivali-on-february-26/articleshow/128290316.cms,"Apple Borivali : Store open date and time



What to expect from Apple Borivali

Apple has announced to open its sixth store in India soon. As revealed by the Cupertino-based company, its next store will be located in Borivali ‚Äì Apple‚Äôs sixth store in India and second in Mumbai. To be called Apple Borivalli, the store will feature a distinctive peacock-inspired visual identity that was first introduced at the September 2025 openings of Apple Hebbal in Bengaluru and Apple Koregaon Park in Pune, and more recently at Apple Noida. The design signals confidence, detail, and a sense of arrival, seen through Apple‚Äôs lens of creativity, the company said in a press release.As announced by Apple, Apple Borivali opens Thursday, February 26 at 1 pm IST. Ahead of opening day, customers are invited to download exclusive Apple Borivali wallpapers, explore a curated Apple Music playlist inspired by the sounds of Mumbai, and learn more about the upcoming store at https://www.apple.com/in/retail/borivali/.Similar to other Apple Stores, customers can explore and purchase Apple‚Äôs latest product lineup, experience new features, and receive expert support from Specialists, Creatives, Geniuses, and dedicated Business teams at Apple Borivali.Customers will also be able to take part in Today at Apple sessions - free, daily, in-store experiences, led by Apple Creatives, designed to help people learn, create, and get more out of their devices.‚ÄúTogether with the Apple Store online, Apple Store app and services such as Apple Pickup, Apple Trade In, Personal Setup, and help with switching to iOS, Apple Borivali deepens Apple‚Äôs commitment to customers in India, offering more personalised, seamless, and secure ways to connect with Apple,‚Äù the release stated.","Apple has announced to open its sixth store in India soon. As revealed by the Cupertino-based company, its next store will be located in Borivali. To be called Apple Borivalli, the store will feature a distinctive peacock-inspired visual identity.","https://static.toiimg.com/thumb/msid-128290306,imgsize-64568,width-400,resizemode-4/apple-to-open-its-sixth-store-in-borivali-on-february-26.jpg"
Elon Musk calls AI models of Anthropic the company that have wiped billions from stock market 'Evil'; says: Your models hate ...,https://timesofindia.indiatimes.com/technology/tech-news/elon-musk-calls-ai-models-of-the-company-that-have-wiped-billions-from-stock-market-evil-says-your-models-hate-/articleshow/128289098.cms,"Elon Musk

Rivalry between Elon Musk and Anthropic



Anthropic faces 'naming trouble' in India



Tesla CEO Elon Musk has now criticised rival AI company Anthropic whose recent AI updates triggered a nearly trillion-dollar selloff in enterprise software stocks and accused its models of being ‚Äòmisanthropic and evil‚Äô. The comments made by Musk came in response to Anthropic‚Äôs announcement on social media platform X (formerly known as twitter) that it has closed $30 billion funding round at the valuation of $380 billion. It is one of the largest private tech raises to date. ‚ÄúWe‚Äôve raised $30B in funding at a $380B post-money valuation. This investment will help us deepen our research, continue to innovate in products, and ensure we have the resources to power our infrastructure expansion as we make Claude available everywhere our customers are,‚Äù wrote Anthropic.In response to this post, Musk alleged that Anthropic‚Äôs AI systems exhibit racial and demographic bias. ‚ÄúYour AI hates Whites & Asians, especially Chinese, heterosexuals and men. This is misanthropic and evil. Fix it. Frankly, I don‚Äôt think there is anything you can do to escape the inevitable irony of Anthropic ending up being Misanthropic. You were doomed to this fate when you chose your name. The Name of the Wind,‚Äù wrote Musk.Anthropic, led by CEO Dario Amodei, is bets known for its Claude family of large language models. On the other hand, Elon Musk‚Äôs AI company xAI competes directly with Calude via its chatbot Grok. The rivalry between the two has intensified in the recent months, particularly after reports that Anthropic cut off xAI‚Äôs access to Claude models.Earlier also Musk has mocked Anthropic‚Äôs name, ‚ÄúAlways worth remembering that fate loves irony. The most ironic outcome for a company named [Anthropic] would be that it is the most misanthropic!‚ÄùAnthropic is now facing legal trouble in India after a local software company claimed prior use of the name ‚ÄòAnthropic‚Äô. As reported by TechCrunch, Anthropic Software an Indian software company founded in 2017, filed a complaint in a commercial court in Karnataka in January this year arguing that the US-based AI firm‚Äôs expansion into India has caused customer confusion. The company is also seeking recognition of its prior use, relief to prevent further confusion and Rs 10 million ($110,000) in damages.Anthropic Software founder and director Mohammad Ayyaz Mulla told TechCrunch that litigation was not the company‚Äôs first choice but became necessary to protect identity. ‚ÄúAs of now, I am exercising my legal right as it‚Äôs causing huge confusion to my customers,‚Äù he said, adding that coexistence would have been preferable if clarity could be achieved.",Tesla CEO Elon Musk has criticised rival AI company Anthropic whose recent AI updates triggered a nearly trillion-dollar selloff in enterprise software stocks. The comments came in response to Anthropic‚Äôs announcement on social media platform X (formerly known as twitter) that it has closed $30 billion funding round at the valuation of $380 billion.,"https://static.toiimg.com/thumb/msid-128289080,imgsize-1340815,width-400,resizemode-4/elon-musk.jpg"
Sam Altman‚Äôs OpenAI accuses Chinese DeepSeek of copying AI models; writes letter to US lawmakers,https://timesofindia.indiatimes.com/technology/tech-news/sam-altmans-openai-accuses-chinese-deepseek-of-copying-ai-models-writes-letter-to-us-lawmakers/articleshow/128288882.cms,"OpenAI's Master Plan for India

What is Distillation tactic that OpenAI is accusing DeepSeek of

What OpenAI is doing

Sam Altman-led OpenAI has accused Chinese DeepSeek of free-riding on the capabilities developed by OpenAI and other US frontier to replicate models and use them for its own training. The ChatGPT-maker has written a letter to the US House Select Committee warning them of DeepSeek using unfair and increasingly sophisticated methods to target OpenAI and America‚Äôs other leading AI companies. ‚ÄúAhead of DeepSeek‚Äôs expected Lunar New Year release of a new, more powerful model, we are providing the Committee with an updated assessment of its evolving distillation tactics,‚Äù OpenAI writes in the memo.‚ÄúOpenAI believes that infrastructure is destiny: chip development, power generation, transmission, and data center capacity will determine which countries can train and deploy frontier systems. This is why we‚Äôre investing through our Stargate Project to expand US AI infrastructure to 10 GW by 2029, and just one year in, we‚Äôre already over halfway toward that Goal,‚Äù the memo stated.‚ÄúBut we are equally focused on ensuring a level playing field, one where the People‚Äôs Republic of China (PRC) can‚Äôt advance autocratic AI by appropriating and repackaging American innovation‚Äù.Distillation tactic that OpenAI is accusing Chinese DeepSeek of involves using an older and more established AI model to review and judge the responses produced by a newer model. Through this process, knowledge and patterns learned by the older system are passed on to the newer one, helping it improve the quality of its answers.‚ÄúWe have observed usage patterns from several major Chinese LLM providers and some university research lab usage that are consistent with, and would be highly beneficial for, creating competitor models through Distillation,‚Äù OpenAI says in the memo.In the memo, OpenAI says that it has observed accounts associated with DeepSeek employees developing methods to circumvent OpenAI‚Äôs access restrictions and access models through obfuscated third-party routers and other ways that mask their source. ‚ÄúWe also know that DeepSeek employees developed code to access US AI models and obtain outputs for distillation in programmatic ways. We believe that DeepSeek also uses third-party routers to access frontier models from other US labs,‚Äù it added.OpenAI says that it believes the best defense is offense: ‚Äúthe best way to ward off a fast-oncoming PRC making headway around the world for autocratic AI is continued investment in American AI leadership and global adoption of responsibly developed, democratic AI.‚Äù‚ÄúWe continue to lead in responsible frontier model innovation, invest across the full AI stack to train and deploy our systems safely, and make powerful AI tools available for free. Adoption of our latest agentic coding model, GPT-5.3-Codex, is up 60% week-over-week. Adoption of ChatGPT is at ~10% monthly growth,‚Äù the company added.",Sam Altman-led OpenAI has accused Chinese DeepSeek of free-riding on the capabilities developed by OpenAI and other US frontier to replicate models and use them for its own training. The ChatGPT-maker has written a letter to the US House Select Committee warning them of DeepSe Seek using unfair and increasingly sophisticated methods to target OpenAI.,"https://static.toiimg.com/thumb/msid-128288872,imgsize-13790,width-400,resizemode-4/deepseek.jpg"
IBM says it will triple hiring for all the jobs that everyone says AI can do; HR head says: If you are going to convince ...,https://timesofindia.indiatimes.com/technology/tech-news/ibm-says-it-will-triple-hiring-for-all-the-jobs-that-everyone-says-ai-can-do-hr-head-says-if-you-are-going-to-convince-/articleshow/128287179.cms,"IBM

Anxiety in the industry over AI and jobs



IBM has reportedly announced that it will triple the entry-level hiring in the US in 2026, even as artificial intelligence raises concerns about the future of early-career jobs. According to a report by Bloomberg, the IBM chief human resources officer Nickel LaMoreaux said that the expansion will cut across departments. Speaking at the Charter‚Äôs Leading with AI Summit in New York, LaMoreaux said, ‚ÄúAnd yes, it‚Äôs for all these jobs that we‚Äôre being told AI can do,‚Äù underscoring the company‚Äôs commitment to investing in human talent despite the increasing automation pressures.LaMoreaux further explained that IBM has revamped the job descriptions for junior positions such as software developers. Since AI tools can now handle the routine coding tasks, entry-level developers spend less time in writing code and more time working directly with customers. In HR, the junior staffers are tasked with intervening when chatbots fall short and correcting outputs and engaging with managers rather hand handling every inquiry themselves. ‚ÄúThe entry-level jobs that you had two to three years ago, AI can do most of them,‚Äù LaMoreaux said.‚ÄúSo, if you‚Äôre going to convince your business leaders that you need to make this investment, then you need to be able to show the real value these individuals can bring now.‚ÄùThe announcement made by IBM comes at a time when fears of job cuts are lingering on the industry. The industry fear that AI could wipe out opportunities for the new graduates. Last year, Anthropic CEO Dario Amodei also warned that half of entry-level jobs may vanish by 2030. Advances in generative AI have already stoked anxiety among college students facing a tough job market.Some companies have cut back on early-career recruitment to save costs, but LaMoreaux cautioned that this could backfire. Without a pipeline of junior hires, firms risk a shortage of mid-level managers in the future, forcing them to poach talent from competitors ‚Äî a more expensive and slower process.Melanie Rosenwasser, Chief People Officer at Dropbox also believe that younger workers are uniquely positioned to thrive in the AI era. ‚ÄúIt‚Äôs like they‚Äôre biking in the Tour de France and the rest of us still have training wheels.‚Äù",IBM has reportedly announced that it will triple the entry-level hiring in the US in 2026. The announcement comes at a time when fears of job cuts are lingering on the industry. The industry fear that AI could wipe out opportunities for the new graduates.,"https://static.toiimg.com/thumb/msid-128287157,imgsize-53794,width-400,resizemode-4/ibm.jpg"
Apple Vision Pro users get official YouTube app,https://timesofindia.indiatimes.com/technology/tech-news/apple-vision-pro-users-get-official-youtube-app/articleshow/128286560.cms,"Apple Vision Pro

Apple iOS 26: Top 5 iOS 26 Features You NEED to See!

Apple launches Vision Pro with M5 chip and Dual Knit Band

YouTube has finally released a dedicated app for Apple Vision Pro after the wait of two years. When the headset was launched, users had to rely on Safari to access YouTube but users missed out on features like offline downloads and optimised playback. The third-party apps briefly filled the gap but were removed for violating YouTube‚Äôs terms of service.The YouTube app for Apple Vision Pro enable users to watch standard videos and YouTube Shorts on a theatre-sized virtual screen. A standout addition is the Spatial tab, which highlights immersive formats such as 3D, VR180, and 360-degree videos. For suers with the latest Vision Pro models powered by the M5 chip, the app also support 8K playback, offering a significant update in visual fidelity. Gesture controls let viewers resize windows, scrub through video and interact more naturally with content.Some of the big streaming services such as Disney+, Amazon Prime Video, Paramount and Peacock launched native VisionOS apps ay the headset debut. YouTube‚Äôs delay raised qestions about its commitment to the platform, especially as early hype around Vision Pro cooled. Recent reports suggest sales have slowed, with only about 45,000 units shipped in Q4 2025, and production scaled back due to weak demand.The YouTube app is now available in the VisionOS App Store and it is compatible with both M2 and M5 chip models. Its arrival marks a significant step in expanding the Vision Pro‚Äôs content ecosystem, giving users access to one of the world‚Äôs largest video platforms in a fully immersive environment.Last year, Apple introduced an upgraded version of its Vision Pro. Coming after two years, the new headset comes equipped with the latest M5 chipset and runs VisionOS 26. The Cupertino-based company claims that the new M5 processor promises improved performance and even faster, smoother, and more responsive experience for Apple Vision Pro users, while introducing new opportunities for developers to create more advanced spatial and immersive experiences. Another key change coming with the new Apple Vision Pro is the dual knit band which, the company claims, helps users achieve an even more comfortable fit.Price of Apple Vision Pro with the M5 chip and Dual Knit Band starts at $3,499. Apple Vision Pro is available in 256GB, 512GB, and 1TB storage capacities.","The YouTube app for Apple Vision Pro enable users to watch standard videos and YouTube Shorts on a theatre-sized virtual screen. A standout addition is the Spatial tab, which highlights immersive formats such as 3D, VR180, and 360-degree videos. The app is now available in the VisionOS App Store and it is compatible with both M2 and M5 chip models.","https://static.toiimg.com/thumb/msid-128286549,imgsize-14584,width-400,resizemode-4/apple-vision-pro.jpg"
Google CEO Sundar Pichai says Gemini 3 Deep Think is getting ‚Äòsignificant upgrade‚Äô: Here‚Äôs what has changed,https://timesofindia.indiatimes.com/technology/tech-news/google-ceo-sundar-pichai-says-gemini-3-deep-think-is-getting-significant-upgrade-heres-what-has-changed/articleshow/128274531.cms,Google CEO Sundar Pichai says Gemini 3 Deep Think is getting ‚Äòsignificant upgrade‚Äô: Here‚Äôs what has changed,Google CEO Sundar Pichai says Gemini 3 Deep Think is getting ‚Äòsignificant upgrade‚Äô: Here‚Äôs what has changed. Google says it is working on a new version of the software that will be called Gemini 4 Deep Think.,"https://static.toiimg.com/thumb/msid-128274518,imgsize-19104,width-400,resizemode-4/gemini-3-deep-think.jpg"
