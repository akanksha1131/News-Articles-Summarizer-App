Article Title,Article Link,Article Text,Article Summary,Article Image
Elon Musk has a reason to celebrate: Tesla’s Model Y becomes Norway’s best-seller car amid challenges,https://timesofindia.indiatimes.com/technology/tech-news/elon-musk-has-a-reason-to-celebrate-teslas-model-y-becomes-norways-best-seller-car-amid-challenges/articleshow/121290376.cms,"Elon Musk’s Tesla Model Y becomes Norway’s best-selling car



Model Y's ongoing success in Norway offers hope for Tesla



Elon Musk remains confident in Tesla’s future despite recent setbacks



Norway: Leading the charge in EV adoption



Also Read |

Tesla's Model Y has made a major breakthrough in Norway, becoming the country's top-selling car. The achievement is not only a victory for Tesla but also reflects Norway's increasing focus on the switch to electric vehicles (EVs). Below, we explore the story of this achievement, its significance for Tesla, and Norway's contribution to the EV revolution worldwide.The success of Elon Musk Tesla Model Y demonstrates Norway's dedication to sustainability and leadership in the transition towards electric cars on a global level. While it has encountered difficulties, Tesla remains confident in the future of its business, and the Model Y continues to blaze a trail in an increasingly transformed automotive sector.The Tesla Model Y has registered over 70,000 in Norway as of April 2025, as per a recent report by TCD. The figure outnumbers some of Norway's most popular and enduring models, such as the Toyota RAV4, Nissan Leaf, Volkswagen Golf, and Toyota Yaris. Through this, the Model Y has effectively gained its position as Norway's best-selling car.This is a remarkable feat given stiff competition from established car brands that have been the market leaders in Norway for long. The success of the Model Y reflects its popularity and the increased use of electric cars in the area.Model Y's success in Norway is not an isolated incident. Based on the TCD report, Tesla's electric SUV has topped the Norwegian automotive market for three years in a row. This repeated success is an outstanding milestone for Tesla, further establishing the Model Y as a Norwegian driver's favorite. Along with this, Tesla was in the news in 2023 by shattering records for the largest number of automobiles sold within one year in Norway. The firm overtook the Volkswagen Beetle's 54-year-old record, which is a testament to the increasing presence of Tesla in the country and its ongoing success.While Norway's success with the Model Y is a plus for Tesla, Tesla itself has struggled over the past few months. The TCD report indicates that Tesla's first-quarter performance was underwhelming, and its stock price and sales numbers worldwide have taken a hit. This slide in market performance has been blamed on several factors, including CEO Elon Musk's political activism and heightened competition in the EV segment.In spite of all these problems, the Model Y's sustained performance in Norway is a ray of hope for Tesla, reasserting the firm's dominance in the electric vehicle segment, particularly in crucial regions such as Scandinavia.Despite challenges Tesla is facing, CEO Elon Musk has been optimistic about the future of the company. In an investor call in April 2025, Musk said, ""We've been through a lot of, a lot of crises over the years and actually been through a lot of near-death experiences,"" and added, ""This is not one of those times. We're not on the ragged edge of death, not even close. I remain extremely optimistic about the future of the company.""Musk's optimism stems from his confidence that Tesla will ride through its present troubles and continue to prosper in the fast-changing electric car industry.Norway's embrace of electric vehicles goes beyond the success of the Model Y. The country has emerged as a global leader in EV adoption, with ambitious goals for the future. According to the TCD report, Norway aims to have all new car sales be electric vehicles by the end of 2025.This rapid shift is complemented by numerous campaigns that remind automobile purchasers to make a switch to electric cars. Norway provides generous rebates for the acquisition of EVs and has established an extensive network of public charging stations. These initiatives have played a fundamental role in Norway's achievement of one of the highest EV penetration rates in the globe.","The Tesla Model Y has registered over 70,000 in Norway as of April 2025, as per a recent report by TCD. Based on the TCD report, Tesla's electric SUV has topped the Norwegian automotive market for three years in a row. The success of the Model Y reflects its popularity and the increased use of electric cars in Norway.","https://static.toiimg.com/thumb/msid-121290506,imgsize-19852,width-400,resizemode-4/Elon-Musk-has-a-reason-to-celebrate-Teslas-Model-Y-becomes-Norways-best-seller-car-amid-challenges.jpg"
'Software Glitch' ... Trump administration acknowledges error in high-profile deportation case after being sued,https://timesofindia.indiatimes.com/technology/tech-news/software-glitch-trump-administration-acknowledges-error-in-high-profile-deportation-case-after-being-sued/articleshow/121300688.cms,"Immigration authority calls it error in software tool, ENFORCE

'Enough Now': Trump Issues 'FINAL ULTIMATUM' To His Own GOP Over Tax Budget Bill | Watch

What is OCG case

In a an ongoing legal battle over deportation, the US Immigration and Customs Enforcement (ICE) has reportedly acknowledged that a key claim it made in response to a lawsuit filed by a Guatemalan man deported to Mexico was based on erroneous information. According to a report in Politico, the admission came in a recent court filing, casting doubt on the Trump administration's defense in a high-stakes class action lawsuit challenging its deportation practices. The lawsuit was filed in March by a Guatemalan man identified in court documents only as O.C.G., who argued he was wrongly deported to Mexico despite expressing fears of persecution there. In its initial response, the Trump administration asserted that O.C.G. himself had stated he was not afraid to be sent to Mexico.However, ICE, as per the report, has now retracted this claim. In a sworn statement submitted to the federal judge overseeing the case, Brian Ortega, assistant field office director for ICE's Enforcement and Removal Operations, stated that ""Upon further investigation ... ICE was unable to identify an officer or officers who asked O.C.G. if he feared a return to Mexico."" The agency attributed the error to a ""software tool"" known as ICE's "" ENFORCE alien removal module ,"" which is used to track deportation cases and allows staff to input comments.The US District Judge Brian Murphy , a Biden appointee based in Massachusetts, previously cited the disputed claim as a reason for not immediately ordering O.C.G.'s return from Mexico. Instead, Judge Murphy reportedly ordered expedited fact-finding, which ultimately led to ICE's admission of the error.The judge noted last month that the discrepancy surrounding O.C.G.'s alleged statement was a significant factor in his decision not to grant immediate relief. This admission, Politico report claims, marks the latest in a series of instances where federal judges have faulted the Trump administration's aggressive deportation efforts for lacking due process. Similar errors have surfaced in other cases, including that of Kilmar Abrego Garcia, a Salvadoran man wrongly deported despite a court order, and Daniel Lozano-Camargo, a Venezuelan man deported to El Salvador in violation of a settlement agreement.O.C.G.'s case is part of a broader legal challenge to the administration's policy of relying on ""third countries"" for deportation. This policy allows authorities to deport immigrants to countries other than their home country if their home country refuses to accept them or if the immigrant has a legitimate fear of returning.The recent admission by ICE is likely to have significant implications for the ongoing lawsuit and further fuels concerns about the accuracy and due process within the U.S. immigration enforcement system under the previous administration.","US Immigration and Customs Enforcement (ICE) has reportedly acknowledged that a key claim it made in response to a lawsuit was based on erroneous information. The admission came in a recent court filing, casting doubt on the Trump administration's defense in a high-stakes class action lawsuit challenging its deportation practices. The lawsuit was filed in March by a Guatemalan man identified in court documents only as O.C.G.","https://static.toiimg.com/thumb/msid-121300692,imgsize-1108719,width-400,resizemode-4/US-tech-firms-dominate-H-1B-approvals-as-Trump-sends-mixed-signals-on-visas.jpg"
"Everything Google announced at I/O 2025: Search's AI mode, 3D video calls, Android smart glasses, and more",https://timesofindia.indiatimes.com/technology/tech-news/everything-google-announced-at-i/o-2025/articleshow/121300646.cms,"Gemini 2.5 models get even smarter

Build with Google Gemini 2.5

Project Starline gets real and a new name, the Google Beam

AI Ultra could be the subscription service no one asked for but they might want it

Google Search gets a complete makeover with AI mode

Ask Search Anything

Google brings smart glasses out of shade with Android XR

Gmail gets AI-powered Smart Replies that actually sound like you

Google Meet adds real-time AI translation

Google's AI Agent is becoming more powerful

Google's vision for a universal AI assistant takes shape with Project Astra

Project Astra | Exploring the Capabilities of a Universal AI Assistant

Google’s Veo and Imagen gets real(er)

Flow | Built with and for creatives

Stitch is an AI-generated UI designer

Android Auto to get video, browser, and more



Google's annual developer conference, the I/O 2025 , arrived with its usual flurry of announcements, demos, and forward-looking promises. This year's I/O, held at the Shoreline Amphitheatre in Mountain View, continued the company's all-in approach on artificial intelligence with significant updates across its product lineup. From an eye-popping $250/month Ultra subscription to Search reimagined with AI, Google delivered a smorgasbord of announcements that ranged from genuinely impressive to slightly concerning for your wallet. Let's do a run down of everything that Google announced at the I/O 2025.Google's Gemini, the AI mode l powering many of the its services, received major upgrades across its lineup. The new Gemini 2.5 Pro now features an ""enhanced reasoning mode"" called Deep Think, which allows the model to consider multiple hypotheses before responding - particularly useful for complex math and coding problems. According to Google, this puts it at the top of the LMArena leaderboard in all categories, with Elo scores up more than 300 points since the first-generation Gemini Pro.Meanwhile, Gemini 2.5 Flash - the more efficient, cost-effective version - has been improved across reasoning, multimodality, code, and long context capabilities. Google claims it's now second only to 2.5 Pro on benchmark tests, while requiring 20-30% fewer tokens for responses. For developers looking for powerful, budget-friendly AI tools, this is the equivalent of getting premium performance at a mid-range price point.Remember Project Starline, Google's futuristic 3D video conferencing booth that promised to make it seem like your conversation partner was sitting right across from you? It's no longer just a research project - it's becoming a real product called Google Beam.The technology uses a six-camera array and AI to merge video streams into a realistic 3D experience viewed on a light field display. Google claims ""near perfect head tracking, down to the millimeter"" at 60 frames per second, all happening in real-time. HP will be the first to release Beam devices for enterprise customers later this year, with companies like Deloitte, Duolingo, and Salesforce already signed up.I'm not saying it's going to replace Zoom overnight, but it might actually make those endless virtual meetings slightly less soul-crushing.In the ""things nobody saw coming"" category, Google announced a new premium subscription tier called AI Ultra, priced at a jaw-dropping $250 per month. Yes, you read that correctly, two hundred and fifty dollars. Monthly.For this Netflix-annual-subscription-times-twenty price tag, subscribers get early access to Google's latest AI tools and unlimited use of features like Deep Research. The package includes 30TB of storage across Google Photos, Drive, and Gmail, plus YouTube Premium and access to experimental features like Project Mariner. New subscribers can get 50% off for the first three months, which still lands at $125 monthly.Google clearly believes some people are willing to pay premium prices for cutting-edge AI tools. The rest of us will just have to wait for these features to eventually trickle down to more affordable tiers.After what Google called ""one of the most successful launches in Search in the past decade"" with AI Overviews, the company is going all-in on transforming how we search the web with AI Mode. This separate tab in Google Search lets users ask longer, more complex questions and follow up with additional queries - essentially turning Google Search into a conversational AI experience.Early testers have been asking queries that are two to three times longer than traditional searches, suggesting users are already adapting to this new paradigm. AI Mode is rolling out to everyone in the US starting this week, powered by Gemini 2.5.Google is also adding features like Deep Search, which expands background queries from tens to hundreds to create comprehensive search responses, and an AI shopping experience that helps users find items and even virtually ""try on"" clothing by uploading a photo of themselves.Following last week's Android Show , where Google previewed some Android 16 features, I/O provided more details on Google's mixed reality plans. The company unveiled its Android XR platform for augmented, mixed, and virtual reality devices.The most interesting development is Project Aura, a prototype of Android XR-powered smart glasses developed with Xreal. These glasses will feature Gemini integration and a large field of view, along with built-in cameras and microphones. Google is also partnering with popular eyewear brands including Samsung, Gentle Monster, and Warby Parker to create more stylish options.Android XR will support features like live translation, directional navigation via a mini Google Maps display, and the ability to view immersive 360-degree videos. After Google Glass and previous AR attempts, this feels like the company's most serious push yet into wearable computing.Google's AI is coming for your inbox, but in a helpful way. Gmail will soon feature personalized smart replies that analyze your writing style and past emails to suggest responses that sound authentically like you. The system considers your typical greetings, tone, and even favorite word choices to generate more relevant replies.With your permission, Gemini can pull information from both your Gmail and Google Drive to craft these responses. For instance, if a friend emails asking about a road trip you've taken, Gemini could reference your past itineraries stored in Docs to suggest a detailed response.The feature will launch through Google Labs in July for English users on web, iOS, and Android platforms. It's either incredibly convenient or slightly unnerving, depending on how you feel about AI mimicking your writing style.Video calls with international colleagues or friends are about to get much easier. Google Meet is adding an AI-powered real-time translation feature that converts your speech into your conversation partner's preferred language nearly instantaneously. The system even attempts to match your tone and cadence while translating.The feature initially supports translation between English and Spanish, with more languages planned for the near future. It's rolling out in beta to Google AI Pro and Ultra subscribers first. This could be a game-changer for global businesses and multilingual families alike.Google's experimental AI agent, Project Mariner, received significant upgrades. The system can now handle up to 10 different tasks simultaneously, from booking flights to researching topics to comparing shopping options.The latest version also introduces a ""teach and repeat"" function, where you can demonstrate a task once, and it learns how to perform similar tasks in the future. Google is bringing Project Mariner's capabilities to developers via the Gemini API, with trusted testers like Automation Anywhere and UiPath already building with it.Remember when AI assistants were just glorified weather forecasters and timer-setters? Project Astra, Google's ambitious universal AI assistant prototype, is aiming to make those days feel like ancient history. At I/O 2025, Google showcased Astra's enhanced capabilities, demonstrating how it can now proactively use your phone's camera to ""see"" the world around you and take action without explicit commands.Google is positioning Astra as the culmination of its AI assistant work, capable of everything from diving into your emails to find bike specs to researching repair information and even calling local shops on your behalf. While some might feel queasy about giving an AI this much access to their digital lives, the productivity gains could be substantial, if you're comfortable with an AI assistant that might occasionally pipe up with unsolicited advice while you're trying to fix your bike chain in peace.The Astra features are already appearing in Gemini Live, which is now available to all Android users and rolling out to iOS starting today.If you thought artificially generated videos look comic, you should have watched Google’s keynote, as it’s new models were previewed. Veo 3, the latest version of Google's AI video generator, now supports audio generation - adding ambient sounds, music, and even dialogue to AI-generated videos. Previous versions could only create silent clips, which wasn't particularly useful in a world where TikTok and YouTube dominate.Imagen 4, Google's text-to-image model, has been improved to generate more photorealistic images with better handling of fine details like fabrics, water droplets, and animal fur. It can now export images in various formats and resolutions up to 2K.Google is also introducing Flow, an AI filmmaking app that builds on these technologies. Flow lets users create eight-second AI-generated video clips based on text prompts or images, with scene-builder tools to stitch clips together for longer videos. Think of it as having a mini film production studio in your pocket - albeit one that sometimes has bizarre interpretations of your creative vision.For developers and designers, Google unveiled Stitch, an AI-powered tool that generates user interfaces based on text descriptions. Users can provide wireframes, rough sketches, or screenshots of other designs to guide Stitch's output, making it easier to quickly prototype app and website designs.While it has more limited capabilities than some competing AI design tools, Stitch provides HTML and CSS markup for the designs it generates, helping bridge the gap between concept and implementation. The experiment is currently available through Google Labs.Google has announced a significant expansion of the app ecosystem for Android Auto, bringing highly anticipated features like video and browser applications, alongside a wider array of weather apps. Users can soon expect to see video and browser applications become available on Android Auto. Google has specified that video apps will require the connected phone to be running Android 16 and will only function on ""select compatible cars,"" and critically, only when the vehicle is parked.","Google's annual developer conference, the I/O 2025, arrived with its usual flurry of announcements, demos, and forward-looking promises. The company continued the company's all-in approach on artificial intelligence with significant updates across its product lineup. From a $250/month Ultra subscription to Search reimagined with AI, Google delivered a smorgasbord of announcements.","https://static.toiimg.com/thumb/msid-121300660,imgsize-985627,width-400,resizemode-4/Google-CEO-Sundar-Pichai-kicking-off-the-I/O-2025.jpg"
Google's AI virtual try-on lets you 'wear' clothes before purchasing,https://timesofindia.indiatimes.com/technology/tech-news/googles-ai-virtual-try-on-lets-you-wear-clothes-before-purchasing/articleshow/121299677.cms,"Google has unveiled AI-powered shopping tools, including a virtual try-on feature allowing users to see clothes on their own photos. Enhanced AI Mode offers personalized product searches with nuanced results. Google will also track prices and complete checkouts via Google Pay."," Enhanced AI Mode offers personalized product searches with nuanced results. Google will also track prices and complete checkouts via Google Pay. Google has unveiled AI-powered shopping tools, including a virtual try-on feature allowing users to see clothes on their own photos.","https://static.toiimg.com/thumb/msid-121299921,imgsize-194889,width-400,resizemode-4/Googles-Try-it-on-feature-is-the-newest-of-AI-features-to-come-to-Search.jpg"
Google’s new ‘AI mode’ turns Search into a chatbot,https://timesofindia.indiatimes.com/technology/tech-news/googles-new-ai-mode-turns-search-into-a-chatbot/articleshow/121300090.cms,"The end of blue links

From search to becoming an agent

AI has begun to replace the search as we know of it, as Google at the I/O announced the “AI Mode.” Available to all US users starting today, CEO Sundar Pichai calls the AI mode , a “total reimagining of search” that will transform’s Google’s headlining product from a link directory into an interactive AI assistant .""Search is bringing AI to more people than any other product in the world,"" Pichai said during the company's annual I/O developer conference, highlighting Google's 8.5 billion daily queries as a massive distribution advantage over competitors.AI Mode will provide users with a chatbot-style experience directly within Google Search, allowing them to ask follow-up questions and receive AI-generated responses rather than just links to websites. The feature was previously available only to limited test users through Google's Labs program.""We launched AI Overviews last year at I/O, and since then there's been a profound shift in how people are using Google Search,"" said Liz Reid, VP and Head of Search at Google. ""People are coming to Google to ask more of their questions, including more complex, longer and multimodal questions.""The new AI Mode is a fundamental shift from Google's traditional approach of displaying webpages in response to queries. Instead, users can have conversational interactions similar to ChatGPT or even Perplexity, with the system providing synthesized answers and allowing follow-up questions.""The search results page was a construct,"" explained Liz Reid, who leads Google's search team, suggesting that the way people have used Google for two decades was largely a response to the web's structure.AI Overviews was beginning of this end, and the AI Mode is coming as users are engaging with artificially generated overviews more than blue links. ""In our biggest markets like the U.S. and India, AI Overviews is driving over 10% increase in usage of Google for the types of queries that show AI Overviews,"" Reid stated.Nick Fox, who runs Google's knowledge and information products, views this shift as natural evolution: ""In the past, search would have been limited to, 'if there's a piece of information out there, I can deliver it back to someone.'"" He emphasized that Google's AI models now ""have the ability to reason, to transform, to connect dots across, to synthesize, to do all these other things that go beyond information retrieval to this notion of intelligence.""Beyond AI Mode, Google also showed off its "" Project Mariner ,"" which can autonomously perform tasks like booking travel or researching topics. The company also announced "" Deep Search "" for comprehensive research and ""Search Live"" for real-time visual assistance.However, there’s still sometime before the blue links disappear altogether. Fox notes that the Google Search still remains the “best experience” for most users, and at least for now, the AI mode will live in a separate tab, and users could use as they like. Although, the features sooner or later will gradually migrate to the traditional search experience.""In three years,"" Fox predicted, ""we will all think about and use Search in a way completely unrecognizable to today's product.""Google plans to first introduce these advanced capabilities in Labs for power users before gradually integrating successful features into the core Search experience.","AI Mode will provide users with a chatbot-style experience directly within Google Search. Users can ask follow-up questions and receive AI-generated responses. The feature was previously available only to limited test users through Google's Labs program. Google also showed off its "" Project Mariner,"" which can autonomously perform tasks like booking travel.","https://static.toiimg.com/thumb/msid-121300182,imgsize-404673,width-400,resizemode-4/Google-Searchs-AI-mode-is-rolling-out-to-all-users-in-the-US.jpg"
Google CEO Sundar Pichai calls this as ‘one of the most successful launches in Search in last 10 years',https://timesofindia.indiatimes.com/technology/tech-news/google-ceo-sundar-pichai-calls-this-as-one-of-the-most-successful-launches-in-search-in-last-10-years/articleshow/121300131.cms,"“It’s one of the most successful launches in Search in the past decade,”

“Since launching last year, AI Overviews have scaled to over 1.5 billion users and are now in 200 countries and territories.” He added “As people use AI Overviews, we see they’re happier with their results, and they search more often.”

Google introduces new AI Mode in Search

AI Mode in Search available in U.S. starting today","Google introduces new AI Mode in Search available in U.S. starting today. “It’s one of the most successful launches in Search in the past decade,” Google says. ‘As people use AI Overviews, we see they’re happier with their results, and they search more often.’","https://static.toiimg.com/thumb/msid-121300127,imgsize-42196,width-400,resizemode-4/CEO-Sundar-Pichai-speaks-at-a-Google-I_O-event.jpg"
Mark Zuckerberg’s Meta seeks mid-trial dismissal of FTC antitrust battle,https://timesofindia.indiatimes.com/technology/tech-news/mark-zuckerbergs-meta-seeks-mid-trial-dismissal-of-ftc-antitrust-battle/articleshow/121251686.cms,"Mark Zuckerberg’s Meta seeks mid-trial dismissal of FTC antitrust battle

New York Post

Meta's legal push to dismiss the FTC case

FTC’s case against Meta: A 'buy or bury' strategy

Meta’s defense strategy and internal turmoil

Mark Zuckerberg takes the stand as FTC trial continues

What comes next for Meta

Also read | AI software development agent Codex released by OpenAI in ChatGPT

Meta , the tech giant behind Facebook, Instagram, and WhatsApp, has requested a federal judge to dismiss the Federal Trade Commission’s (FTC) high-profile antitrust case, just as the trial approaches a critical phase. According to the, the case, which began in early April, represents one of the most significant regulatory challenges faced by Meta in its history, potentially resulting in the breakup of the company’s social media empire.Meta's move to dismiss the case comes after the FTC rested its side of the argument, asserting that the company holds an illegal monopoly over the social networking market, particularly those platforms focused on friends-and-family connections. Meta, however, argues that the FTC's case is based on a flawed market definition and ignores the intense competition it faces from newer platforms like TikTok, YouTube, and Elon Musk’s X (formerly known as Twitter).In a court filing late Thursday, Meta reiterated its stance that the FTC has failed to meet the legal standards required to prove its antitrust allegations. The company’s legal team argues that the FTC has fundamentally mischaracterized the social media market, claiming that the agency's definition is overly narrow and excludes significant competitors.“After five weeks of trial, it is clear that the FTC has failed to meet the legal standard required under antitrust law,” a Meta spokesperson said in a statement on Friday. “Regardless, we will present our case to show what every 17-year-old in the world knows: Instagram competes with TikTok (and YouTube and X and many other apps).”Meta claims that it faces substantial competition from a wide range of digital platforms, including short-video giant TikTok, video-sharing platform YouTube, and Elon Musk’s X. These platforms, Meta argues, all compete for user engagement, advertising revenue, and market share, undercutting the FTC’s claim that Meta has maintained an unlawful monopoly.The FTC’s antitrust lawsuit, which was first filed in December 2020, centers on Meta’s acquisitions of Instagram in 2012 and WhatsApp in 2014. The agency claims that Meta pursued a deliberate “buy or bury” strategy, acquiring these fast-growing competitors to neutralize potential threats to its dominant position in the social networking market.In its filing, the FTC pointed to internal Meta communications as evidence of this strategy. This includes a 2012 email from Meta CEO Mark Zuckerberg suggesting that buying Instagram would “neutralize a competitor.” The FTC further argues that these acquisitions reduced consumer choice and stifled innovation, limiting competition in the rapidly evolving social media industry.The FTC's case aims to convince U.S. District Judge James Boasberg to order Meta to spin off Instagram and WhatsApp, effectively dismantling the company's integrated social media ecosystem.Meta's defense in the trial has focused on presenting itself as a company that supports innovation and benefits consumers. In its Thursday filing, the company argued that its acquisition of Instagram enabled massive growth, which in turn delivered significant benefits to users.“Meta’s acquisition of Instagram enabled massive growth – with correspondingly massive benefits for US consumers,” the company stated in its court filing.However, the trial has also brought to light internal documents that may complicate Meta’s defense. For instance, a 2018 email from an unnamed Instagram executive warned that ""fake engagement could be in the range of 40%,"" potentially undermining Meta's claims about the platform’s integrity and user trust.Mark Zuckerberg himself was the first witness called by the FTC as the trial opened, highlighting the personal stakes for the Meta CEO. During his testimony, Zuckerberg sought to portray Meta as a company facing fierce competition, rather than a monopoly crushing potential rivals.Earlier in the trial, Instagram co-founder Kevin Systrom testified that he felt Zuckerberg viewed Instagram’s rapid growth as a potential threat to Facebook’s dominance after the acquisition, further fueling the FTC’s argument that Meta's mergers were designed to stifle competition.The 10-week non-jury trial, which is expected to conclude in June, will be followed by final briefs from both the FTC and Meta. If Judge Boasberg sides with the FTC, a second trial will be held to determine appropriate remedies, potentially including the forced divestiture of Instagram and WhatsApp.Meta will continue presenting its defense when the trial resumes on Monday. The company’s attempt to dismiss the case outright remains a long shot, as the judge may choose to let the case proceed to its scheduled conclusion before issuing a ruling.","The FTC's antitrust lawsuit centers on Meta’s acquisitions of Instagram in 2012 and WhatsApp in 2014. The agency claims that Meta pursued a deliberate “buy or bury” strategy, acquiring these fast-growing competitors to neutralize potential threats to its dominant position in the social networking market. Meta argues that the FTC's case is based on a flawed market definition and ignores the intense competition it faces.","https://static.toiimg.com/thumb/msid-121252048,imgsize-33102,width-400,resizemode-4/Mark-Zuckerbergs-Meta-seeks-mid-trial-dismissal-of-FTC-antitrust-battle.jpg"
Jeff Bezos and Lauren Sanchez’s Venice wedding could cost up to $11 million: Report,https://timesofindia.indiatimes.com/technology/tech-news/jeff-bezos-and-lauren-sanchezs-venice-wedding-could-cost-up-to-11-million-report/articleshow/121263184.cms,"Jeff Bezos and Lauren Sanchez are set to wed in Venice, Italy, from June 24-26, 2026, in an intimate ceremony with under 200 guests. Despite earlier rumors of extravagant spending, reports suggest the wedding will cost between $9.5 and $11 million.","Jeff Bezos and Lauren Sanchez are set to wed in Venice, Italy, from June 24-26, 2026, in an intimate ceremony with under 200 guests. Despite earlier rumors of extravagant spending, reports suggest the wedding will cost between $9.5 and $11 million.","https://static.toiimg.com/thumb/msid-121263176,imgsize-28216,width-400,resizemode-4/Jeff-Bezos-and-Lauren-Sanchezs-Venice-wedding-could-cost-up-to-11-million-Report.jpg"
Elon Musk was a Microsoft intern! He remembers it in conversation with Satya Nadella,https://timesofindia.indiatimes.com/technology/tech-news/elon-musk-was-a-microsoft-intern-he-remembers-it-in-conversation-with-satya-nadella/articleshow/121289724.cms,"Elon Musk was a Microsoft intern! He remembers it in conversation with Satya Nadella

Elon Musk’s early connection with Microsoft

“I know you started off as an intern at Microsoft. You were a PC gamer then—and still are.”

xAI’s Grok 3 AI models now available on Microsoft Azure

Technical insights into Grok 3.5

Significance of the Microsoft-xAI collaboration

Free access to Grok AI on Azure available this June

Future outlook and industry impact

Also read | Elon Musk under fire: Senators demand investigation into Starlink trade deals

In a notable event at the Microsoft Build 2025 developer conference, Elon Musk , CEO of xAI and Tesla, joined Microsoft CEO Satya Nadella to announce the integration of xAI’s flagship Grok 3 AI models on Microsoft Azure. This announcement marks a significant step in the evolving artificial intelligence landscape, bringing together two major technology powerhouses. The Grok models will be accessible for free throughout June on the Azure AI Foundry platform, which also features AI offerings from industry leaders such as OpenAI, Meta, and Hugging Face.This collaboration highlights not only technological innovation but also the historical ties between Musk and Microsoft, recalling Musk’s early programming days as a Microsoft intern. This detailed report covers all aspects of the announcement, the technology behind Grok, the significance of this partnership, and the future prospects of AI development on Azure.During the Build conference, Satya Nadella took a moment to reflect on Elon Musk’s early career. Nadella reminded the audience of Musk’s internship at Microsoft, stating,Musk responded warmly, sharing memories of his beginnings before Windows with MS-DOS on the earliest IBM PCs. He highlighted the technological limitations of that era, recalling how memory upgrades from 128k to 256k were significant milestones. Musk also described programming video games in DOS and later working with Windows 3.1, emphasizing his foundational experience in software development which shaped his future ventures.The core of the announcement focused on the launch of Grok 3, xAI’s advanced family of AI models, now integrated with Microsoft Azure’s cloud infrastructure. Nadella introduced Grok as “a family of models that are both responsive and capable of reasoning,” expressing enthusiasm about its deployment on Azure AI Foundry, Microsoft’s AI platform that offers scalable, managed AI services to developers and enterprises worldwide.The availability of Grok 3 and Grok 3 Mini on Azure aims to broaden access to cutting-edge AI capabilities. Microsoft will provide these models with service-level agreements consistent with their other AI offerings, and billing will be streamlined through Microsoft’s standard Azure framework. This ensures ease of integration for enterprises already operating within the Azure ecosystem.Elon Musk elaborated on the forthcoming Grok 3.5 model during the conversation. He described it as an AI designed to “reason from first principles,” a philosophical approach emphasizing fundamental truths and axioms as the basis for knowledge and problem-solving. Musk explained that the model’s architecture is grounded in fundamental physics, allowing it to apply these principles across different reasoning domains with an aim to minimize error and approach accurate understanding.This emphasis on physics-based reasoning sets Grok apart from many AI models that rely primarily on pattern recognition and statistical inference. By integrating first-principles reasoning, Grok 3.5 aspires to provide more reliable, consistent outputs, potentially enhancing applications across diverse fields such as autonomous vehicles, space exploration, and customer service.The integration of Grok into Azure represents a strategic alliance that leverages Microsoft’s extensive cloud infrastructure and xAI’s innovative AI research. This collaboration extends the reach of Musk’s xAI beyond standalone systems, embedding it within one of the largest and most trusted cloud platforms globally.Azure AI Foundry already hosts models from major AI developers like OpenAI, Meta, and Hugging Face, making it a hub for AI innovation and adoption. Grok’s addition to this ecosystem reflects Microsoft’s commitment to providing diverse AI options to developers and enterprises.The partnership also comes amid industry discussions regarding the influence of large tech firms on AI development. Musk’s previous criticisms of Microsoft’s role in OpenAI’s operations add a layer of complexity to this collaboration, underscoring the nuanced relationships shaping the AI industry.Microsoft announced that Grok models will be available free of charge throughout June, allowing developers, researchers, and businesses to explore and experiment with xAI’s technology. This limited free access serves to increase adoption and foster community feedback, critical for refining AI capabilities and expanding real-world applications.Post-June, Grok’s services will continue under Microsoft’s commercial terms, integrated fully within the Azure billing and support system. This seamless integration facilitates enterprise-grade deployment, enabling customers to incorporate Grok-powered AI into their existing workflows with minimal friction.The collaboration between Microsoft and xAI marks a pivotal moment in AI development, demonstrating the growing importance of cloud platforms as hubs for AI innovation and distribution. By combining xAI’s first-principles reasoning models with Microsoft’s global cloud reach, this partnership is poised to accelerate the deployment of advanced AI solutions across industries.As AI technologies continue to evolve rapidly, partnerships like this provide essential infrastructure and support for scalable AI applications in sectors such as automotive, aerospace, healthcare, and customer experience. The free access period in June offers the broader tech community an opportunity to assess Grok’s capabilities and potential impact.","Elon Musk, CEO of xAI and Tesla, joined Microsoft CEO Satya Nadella to announce the integration of x AI’s flagship Grok 3 AI models on Microsoft Azure. This announcement marks a significant step in the evolving artificial intelligence landscape, bringing together two major technology powerhouses. The Grok models will be accessible for free throughout June on the Azure AI Foundry platform, which also features AI offerings from industry leaders.","https://static.toiimg.com/thumb/msid-121290880,imgsize-48770,width-400,resizemode-4/Elon-Musk-was-a-Microsoft-intern-He-remembers-it-in-conversation-with-Satya-Nadella.jpg"
Duolingo CEO Luis von Ahn makes a prediction on how AI will change schools in future,https://timesofindia.indiatimes.com/technology/tech-news/duolingo-ceo-luis-von-ahn-makes-a-prediction-on-how-ai-will-change-schools-in-future/articleshow/121290768.cms,"Duolingo CEO Luis von Ahn feels that AI will take over teaching



Schools won’t disappear, but their role will change: Duolingo CEO Luis von Ahn



Duolingo CEO Luis von Ann recently predicted that artificial intelligence (AI) will fundamentally transform education, shifting the role of schools from traditional learning institutions to childcare and supervised spaces. As reported by Business Insider, speaking at the No Priors podcast, von Ahn stressed on the fact that AI’s scalability makes it more efficient than human teachers and it can be easily used for personalised education. ""Education is going to change. It's just a lot more scalable to teach with AI than with teachers,” von Ahn said.Von Ahn suggests that AI will increasingly handle the core instruction in schools. He believes that AI can deliver personalised education more effectively than traditional classroom models with teachers. AI system can be designed to precisely track individual student progress, identify areas where they struggle and then tailor the learning experience accordingly.While Von Ahn does not believe schools will vanish, he foresees a future where AI tutors handle most of the teaching, while schools primarily serve as safe environments for children. He explained that AI can track individual student performance in real time, adjusting lesson plans to match each child’s learning pace—something human teachers struggle to do in large classrooms.“That doesn't mean the teachers are going to go away. You still need people to take care of the students. I also don't think schools are going to go away because you still need childcare,” von Ahn said on the podcast.This doesn't mean teachers will become obsolete, according to von Ahn. Instead, their responsibilities may evolve. Teachers could transition from primarily delivering instruction to supervising students, providing guidance, and fostering social and emotional development.Von Ahn also points out that the integration of AI in education is already happening. Duolingo, for example, is restructuring its operations to embrace an ""AI-first"" approach. This includes using AI for tasks previously done by contractors and incorporating AI into employee performance reviews.","Duolingo CEO Luis von Ahn predicts that AI will transform education. He believes that AI can deliver personalised education more effectively than traditional classroom models with teachers. AI system can be designed to precisely track individual student progress, identify areas where they struggle and then tailor the learning experience accordingly.","https://static.toiimg.com/thumb/msid-121290741,imgsize-2095823,width-400,resizemode-4/Duolingos-CEO-Luis-von-Ahn.jpg"
Android 16 QPR1 Beta 1 starts rolling out: Material 3 Expressive redesign that Google calls 'its biggest updates in years'; eligible Pixel devices and more,https://timesofindia.indiatimes.com/technology/tech-news/android-16-qpr1-beta-1-starts-rolling-out-material-3-expressive-redesign-that-google-calls-its-biggest-updates-in-years-eligible-pixel-devices-and-more/articleshow/121299970.cms,"What is Material 3 Expressive redesign that comes with Android 16

Should you download Android 16 QPR1 Beta 1

Who will get Android 16 QPR1 Beta 1

How to report bugs in Android 16 QPR1 Beta 1

Which are the Pixel devices getting Android 16 QPR1 Beta 1",Summarize: What is Material 3 Expressive redesign that comes with Android 16. How to report bugs in Android 16 QPR1 Beta 1. Which are the Pixel devices getting Android 16QPR1 beta 1? How to get the latest version of Android.,"https://static.toiimg.com/thumb/msid-121299969,imgsize-21798,width-400,resizemode-4/Android-Maharashtra-Times.jpg"
Gmail’s smart replies are getting ‘smarter’; here’s how the improved AI feature will work,https://timesofindia.indiatimes.com/technology/tech-news/gmails-smart-replies-are-getting-smarter-heres-how-the-improved-ai-feature-will-work/articleshow/121299882.cms,"Gmail personalised smart replies: How it will work



“Replying to email often means referencing details buried in other files, or re-reading long threads just to gather context. And it takes time to write in the way you want. Personalised smart replies in Gmail will help you draft emails that match your specific context and your tone. By pulling from your past emails and Google Drive, Gemini provides response suggestions with specific details that are more relevant and on point, eliminating the need to dig through your inbox and files yourself. Crucially, it also adapts to your typical tone — whether crisp and formal or warm and conversational — so your replies sound authentically like you.”

Gmail's smart replies will now be more personalised. At its latest annual developer conference, Google I/O 2025 , the company’s CEO, Sundar Pichai , announced that the feature will now be able to pull information from the user’s inbox and Google Drive with the help of Gemini AI. During the event, Pichai showed a demo of him replying to a co-worker’s email about a holiday to show how Gmail will personalise replies based on the user. These enhancements build on Google’s ""contextual"" upgrade to smart replies introduced last year. With these new changes, smart replies are expected to be able to incorporate a broader range of context than before. With this update, Google aims to make Gemini better match the user’s tone and style, making suggested replies more relevant and tailored to individual user communication patterns.This update will allow for longer responses, moving beyond short phrases. Earlier, smart replies could only draw information from the current Gmail thread.In a blog post, Google writes:The company also noted that the feature will be available generally later this year.Apart from this, Gmail is getting more AI‑based features, which include an inbox cleanup tool and faster appointment scheduling. The inbox cleanup feature lets users command Gemini to delete or archive unwanted emails, such as “Delete all my unread emails from The Groomed Paw from last year”—and declutter their inbox with a single click.Faster appointment scheduling detects when a user is arranging a meeting and prompts them to share available time slots directly within Gmail, allowing external clients or contacts to book without leaving the inbox. The company noted that both features will be generally available next quarter.","Gmail's smart replies will now be more personalised. The feature will be able to pull information from the user’s inbox and Google Drive with the help of Gemini AI. Gmail is getting more AI‑based features, which include an inbox cleanup tool and faster appointment scheduling.","https://static.toiimg.com/thumb/msid-121299874,imgsize-34332,width-400,resizemode-4/Gmails-smart-replies-are-getting-smarter-heres-how-the-improved-AI-feature-will-work.jpg"
"Google I/O 2025: Gemini 2.5 Pro gets improved reasoning, audio features and multilingual support",https://timesofindia.indiatimes.com/technology/tech-news/google-i/0-2025-gemini-2-5-pro-gets-improved-reasoning-audio-features-and-multilingual-support/articleshow/121299545.cms,"Native audio, emotional dialogue and multilingual support

Detect user emotions and respond accordingly (Affective Dialogue)

Ignore background noise (Proactive Audio)

Handle more complex voice tasks (Thinking in the Live API)

New ‘Deep Think’ for complex tasks

Gemini 2.5 Flash gets faster and more efficient

At Google I/O 2025, the company announced new updates to its Gemini 2.5 model series adding more powerful reasoning, native audio output, security upgrades, and improved tools for developers. “In March, we announced Gemini 2.5 Pro , our most intelligent model yet…Today, We’re bringing new capabilities to 2.5 Pro and 2.5 Flash,” Google said, announcing the new updates.The upgraded Gemini 2.5 Pro model now tops performance charts, including WebDev Arena for coding and LMArena for human preference testing. It also features a 1 million-token context window, which allows it to handle longer inputs and video understanding tasks.Google said that thanks to LearnLM — a version of Gemini developed with educational experts — the model now leads in learning-related tasks as well.“Educators and experts preferred Gemini 2.5 Pro over other models across a diverse range of scenarios,” the company said.Google also introduced native audio output for a more natural AI experience. Gemini can now speak with different tones, accents, and styles — such as a dramatic voice when telling a story. It can also:The text-to-speech tool now supports multiple speakers and over 24 languages, and it can switch between languages mid-conversation. These features will be available later today through the Gemini API.Google said that it is testing an enhanced reasoning mode called Deep Think, which helps Gemini consider multiple answers before responding. It's aimed at tough challenges like advanced math and programming.“We’re starting to test an enhanced reasoning mode called Deep Think,” the company said.“We’re taking extra time to conduct more frontier safety evaluations and get further input from safety experts.”Deep Think is already leading benchmarks like the 2025 USAMO (math), LiveCodeBench (coding), and MMMU (multimodal reasoning).Gemini 2.5 Flash, the lightweight version of the model, now uses 20–30% fewer tokens while improving performance across reasoning, code, and multimodal tasks, the company announced. It is now available in the Gemini app, Google AI Studio , and Vertex AI.A general release of the updated model is expected in early June, with 2.5 Pro following soon after.","Gemini 2.5 Pro model now tops performance charts, including WebDev Arena for coding and LMArena for human preference testing. It also features a 1 million- token context window, which allows it to handle longer inputs and video understanding tasks. Google also introduced native audio output for a more natural AI experience.","https://static.toiimg.com/thumb/msid-121299543,imgsize-25830,width-400,resizemode-4/Google-I/0-2025-Gemini-2-5-Pro-gets-improved-reasoning-audio-features-and-multilingual-support.jpg"
Google Meet gets real-time live translation capabilities; here’s how it works,https://timesofindia.indiatimes.com/technology/tech-news/google-meet-gets-real-time-live-translation-capabilities-heres-how-it-works/articleshow/121299476.cms,"Use Google Meet speech translation to connect in near real-time across languages

Google Meet real-time live translation: Availability



“Translation in English and Spanish is rolling out to Google AI Pro and Ultra subscribers in beta, with more languages coming in the next few weeks. This will come to Workspace business customers for early testing this year.”

Google Meet real-time live translation: Here’s how it will work



“You can see how well it matches the speaker’s tone and expressions,”

Google Meet is getting new live speech translation capabilities, which will be powered by Gemini AI . The company announced these new capabilities during the keynote speech at its annual developer conference, Google I/O 2025 . This feature will translate spoken words into a conversation partner's preferred language in real-time. Google claims that the AI-generated translation will preserve the original speaker's voice, tone, and expression. During the event, the company’s CEO, Sundar Pichai , showed a demonstration where an English speaker can be seen communicating with a Spanish speaker, with Meet providing AI-generated English translations that maintained vocal inflexions, and vice versa. To compare, Microsoft Teams introduced a similar AI translation feature in a preview earlier this year.In a vlog post, the company writes:As per the video demo, rather than just displaying translated captions, Google Meet’s new real‑time translation will capture a speaker’s voice and convert it into another language, while retaining their unique tone, inflexion, and speaking style.Pichai said at the end of the demonstration.Powered by Gemini AI, the feature delivers low‑latency processing and natural voice synthesis so the translated output sounds like the original speaker instead of a generic text‑to‑speech voice.In the demo, an English speaker and a Spanish speaker held a fluent conversation as each person’s voice was translated live, creating a seamless, personalised interaction.","Google Meet is getting new live speech translation capabilities, which will be powered by Gemini AI. This feature will translate spoken words into a conversation partner's preferred language in real-time. Google claims the AI- generated translation will preserve the original speaker's voice, tone, and expression.","https://static.toiimg.com/thumb/msid-121299477,imgsize-11478,width-400,resizemode-4/Google-Meet-gets-real-time-live-translation-capabilities-heres-how-it-works.jpg"
"Google I/O 2025: Google announces new 'AI Ultra' subscription plan: Price, benefits and all other details",https://timesofindia.indiatimes.com/technology/tech-news/google-i/o-2025-google-announces-new-ai-ultra-subscription-plan-price-benefits-and-all-other-details/articleshow/121299278.cms,"Google AI Ultra plan benefits for the subscribers



Google renames AI Premium plan to AI Pro, and adds new benefits

Google, at I/O 2025, announced its premium AI subscription plan , Google AI Ultra , on May 20, 2025, for $249.99 (around Rs 21,380) per month, positioning it as a 'VIP pass' to the company's most powerful AI capabilities. First-time subscribers can receive 50% off for the first three months.The plan targets filmmakers, developers, and creative professionals demanding the highest level of access to Google's AI ecosystem, according to Shimrit Ben-Yair, Vice President of Google Photos and Google One. Google AI Ultra subscribers will receive expanded access to the Gemini app with the highest usage limits for Deep Research and video generation through Veo 2, with early access to the upcoming Veo 3 model. In the coming weeks, subscribers will also gain access to a new enhanced reasoning mode called Deep Think in 2.5 Pro.The subscription includes Flow, an AI filmmaking tool utilizing Google DeepMind's advanced models, enabling 1080p video generation and advanced camera controls. Ultra subscribers also receive Whisk, a visualization tool that can transform images into eight-second videos.Additional benefits include 30TB of storage across Google services, an individual YouTube Premium subscription , and early access to Gemini in Chrome starting tomorrow.Google's existing AI Premium plan, now renamed Google AI Pro , will receive upgrades at no additional cost. These include access to Flow's AI filmmaking capabilities with the Veo 2 model and early access to Gemini in Chrome.The company also announced expanded access to free Google AI Pro subscriptions for university students in Japan, Brazil, Indonesia, and the United Kingdom, in addition to the United States.Google AI Ultra is currently available in the US, with plans to launch in additional countries soon.","Google's AI Premium plan, now renamed Google AI Pro, will receive upgrades at no additional cost. Google AI Ultra subscribers will receive expanded access to the Gemini app with the highest usage limits for Deep Research and video generation through Veo 2. Subscribers will also gain access to a new enhanced reasoning mode called Deep Think in 2.5 Pro.","https://static.toiimg.com/thumb/msid-121299279,imgsize-721809,width-400,resizemode-4/Google-AI-Ultra.jpg"
Google I/O 2025: Xreal’s Project Aura are the second pair of smart glasses to run Google's Android XR Operating System,https://timesofindia.indiatimes.com/technology/tech-news/google-i/o-2025-xreals-project-aura-are-the-second-pair-of-smart-glasses-to-run-googles-android-xr-operating-system/articleshow/121299113.cms,"Google positions Android XR to compete with Meta and Apple

Xreal announced Project Aura, a new pair of extended reality (XR) smart glasses running Google 's Android XR operating system , at Google's I/O 2025 conference on Tuesday. This marks only the second official device to use Google's XR platform following Samsung's Project Moohan headset announced earlier this year.The lightweight ""optical see-through"" glasses represent a significant partnership between Google, Xreal, and Qualcomm as tech giants race to establish dominance in the emerging XR space. While few technical specifications were released, Xreal confirmed the glasses will utilize Qualcomm's Snapdragon XR chips specifically designed for XR hardware.""By combining our platform with XREAL's leadership in portable XR hardware, we're expanding spatial experiences to OST form-factors that are truly intuitive and accessible, representing a pivotal moment in our ecosystem,"" said Hugo Swart, Google's Senior Director of XR Ecosystem, in a press release.The strategic partnership positions Google to challenge Meta and Apple in the XR market. For Google, securing more devices on Android XR increases the platform's appeal to developers building applications for these new computing devices. Meanwhile, Xreal gains access to cutting-edge technology and Google's marketing power.Unlike bulky headsets like Apple's $3,500 Vision Pro, Project Aura maintains Xreal's focus on lightweight, tethered devices that connect to other hardware to run. Product renders show what appear to be cameras in the hinges and nose bridge, along with microphones and control buttons in the temples.Xreal CEO Chi Xu called the collaboration ""a breakthrough moment for real-world XR,"" highlighting the merger of Google's platform, Qualcomm's chipsets, and Xreal's optical expertise.Further details about Project Aura will be revealed at the Augmented World Expo in early June, with no pricing or release timeline currently announced.","Xreal announced Project Aura, a new pair of extended reality (XR) smart glasses running Google's Android XR operating system. This marks only the second official device to use Google's XR platform following Samsung's Project Moohan headset announced earlier this year.","https://static.toiimg.com/thumb/msid-121299110,imgsize-178869,width-400,resizemode-4/Xreal-Project-Aura.jpg"
Else China will ...: David Sacks answer to Democrats on why the US is putting data centers and research hubs in Dubai,https://timesofindia.indiatimes.com/technology/tech-news/else-china-will-david-sacks-answer-to-democrats-on-why-the-us-is-putting-data-centers-and-research-hubs-in-dubai/articleshow/121298913.cms,"US President Donald Trump in UAE

The United States and United Arab Emirates (UAE) have announced partnership to build a massive data center complex in Abu Dhabi to advance artificial intelligence (AI) capabilities with 5-gigawatts of capacity. The agreement, announced during the US President Donald Trump’s recent visit to the UAE, will mark the largest data center deployment outside of the United States, according to the Commerce Department. The project is also expected to expand the footprint of American AI and cloud companies in the Middle East, allowing them to better serve the global south.However, some key Senate Democrats have reportedly urged the Trump administration to revisit new artificial intelligence deals with Saudi Arabia and the United Arab Emirates. According to a report in Bloomberg, these Democrats say that the expanded sales of AI chips to the Middle Eastern countries risk exposing advanced technology to China and Russia, while potentially limiting supplies available for American companies. Incidentally, the US has restricted sales of advanced AI semiconductors to Saudi Arabia and the UAE since 2023, as part of a broader effort to prevent China from accessing banned American technology via intermediaries.Now in a long post on Twitter, David O Sacks the 'White House AI and Crypto Czar', a newly-created role with the goal of building a legal framework for the cryptocurrency industry, defended Trump's AI data center partnership with UAE. He wrote that if the US does not take this deal, it will be Advantage China, which has been more than eager to offer Huawei+DeepSeek tech stack to UAE.David Sacks wrote his post in response to Ro Khanna's address where he questioned partnership and asked: Why are we putting data centers and research hubs in Dubai? We should have those high-paying new technology jobs in the United States. What happened to “America First”?Quoting Ro Khanna, David Sacks wrote that ""some Democrats, including my friend Rep. Ro Khanna, are asking why we aren’t putting the new AI data centers in Ohio and Pennsylvania. Actually we are doing that. The key to building new data centers is easier permitting and more power generation, both of which were effectively impossible under the Biden administration."" He added, ""The Trump administration is alleviating the bottlenecks. As the President says, we are going to “Drill, Baby, Drill” — and we are also going to Build, Baby, Build. I hope Democrats will cooperate with us on this agenda; let’s do it together for the betterment of the USA.""As for doing it in UAE and not America, Sacks wrote, ""With respect to UAE, it’s important to understand that the deal has a matching investment provision, so UAE will fund the build-out of AI infrastructure in the U.S. at least as large and powerful as that in UAE. And in UAE, the vast majority of the compute will be owned & operated by American cloud companies, to serve the region as well as the Global South. These are America First deals that drive investment into the U.S., improve our trade balance, and lock in American technology as the global standard.""He went on to add that if the US does not take this deal, China will. ""The alternative is for the U.S. to reject the resource-rich Gulf States and drive them into the arms of China, which is eager to sell them a Huawei+DeepSeek tech stack. And China won’t gainsay the opportunity by asking local partners why they aren’t building their data centers in Beijing or Shanghai instead. China will just fill out the purchase orders and ship the chips, making Chinese technology the standard. We shouldn’t let this happen. We still have a limited window to ensure American technology dominance in global AI infrastructure. Let’s seize it.""","The United States and United Arab Emirates have announced partnership to build a massive data center complex in Abu Dhabi. The agreement, announced during the US President Donald Trump’s recent visit to the UAE, will mark the largest data center deployment outside of the United States. The project is also expected to expand the footprint of American AI and cloud companies in the Middle East.","https://static.toiimg.com/thumb/msid-121298920,imgsize-29908,width-400,resizemode-4/U-S-President-Trump-visits-UAE.jpg"
